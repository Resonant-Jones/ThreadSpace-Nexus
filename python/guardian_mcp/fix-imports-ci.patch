diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
new file mode 100644
index 0000000000000000000000000000000000000000..8621811f9f83bee795eba688f5a5dac6f3e0eebd
--- /dev/null
+++ b/.github/workflows/ci.yml
@@ -0,0 +1,17 @@
+name: CI
+on: [push, pull_request]
+jobs:
+  build:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v3
+      - uses: actions/setup-python@v4
+        with:
+          python-version: '3.10'
+      - run: pip install -e .[dev] pip-audit
+      - run: black --check .
+      - run: flake8
+      - run: mypy guardian plugins || true
+      - run: pytest
+      - run: pip-audit
+      - run: python -m build
diff --git a/CHANGELOG.md b/CHANGELOG.md
index b030bdb40f20b6ed5bd0333acd459a6d78c96d19..5b9c69181315f20469f45f034b4c5fc4265a316c 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -41,51 +41,51 @@ and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0
 - System initialization and configuration
 - Health monitoring and reporting
 
 ### Developer Tools
 - Makefile for common operations
 - Test runner with comprehensive reporting
 - Development environment setup scripts
 - Plugin initialization tools
 - Documentation generation
 
 ### Testing
 - System integration tests
 - Agent interaction tests
 - Plugin lifecycle tests
 - Error handling and recovery tests
 - Performance benchmarks
 
 ### Documentation
 - System architecture overview
 - Component interaction diagrams
 - Plugin development guide
 - API documentation
 - Contributing guidelines
 - Code of conduct
 
-## [0.1.0] - YYYY-MM-DD
+## [0.1.0] - 2024-06-30
 
 ### Added
 - Initial release
 - Basic system architecture
 - Core agent implementations
 - Plugin system foundation
 - Development tools setup
 
 ### Security
 - Basic plugin sandboxing
 - Thread isolation
 - Memory protection
 - Access control implementation
 
 ### Changed
 - N/A (Initial release)
 
 ### Deprecated
 - N/A (Initial release)
 
 ### Removed
 - N/A (Initial release)
 
 ### Fixed
 - N/A (Initial release)
diff --git a/demo/system_demo.py b/demo/system_demo.py
index 8f0b26146655fac62cf2e5418cf1f128a53fe0e8..f048f6c8e61c113b0e2dcfab38df3f20af4b5fbd 100644
--- a/demo/system_demo.py
+++ b/demo/system_demo.py
@@ -1,274 +1,274 @@
 """
 Threadspace System Demo
 ---------------------
 Demonstrates full system lifecycle and component integration.
 """
 
 import asyncio
 import json
 import logging
 import time
 from datetime import datetime
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 from guardian.codex_awareness import CodexAwareness
 from guardian.metacognition import MetacognitionEngine
 from guardian.plugin_loader import PluginLoader
 from guardian.system_init import SystemInitializer
 from guardian.threads.thread_manager import ThreadManager
+from guardian.logging_config import configure_logging
 
 # Configure logging
-logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
-)
+configure_logging()
 logger = logging.getLogger(__name__)
 
+
 class SystemDemo:
     """Demonstrates system functionality."""
-    
+
     def __init__(self):
         self.initializer = SystemInitializer()
         self.thread_manager = ThreadManager()
         self.plugin_loader = PluginLoader()
         self.codex = CodexAwareness()
         self.metacognition = MetacognitionEngine()
-    
+
     async def run_demo(self):
         """Run the system demonstration."""
         try:
             logger.info("Starting Threadspace System Demo")
-            
+
             # 1. System Initialization
             logger.info("\n=== System Initialization ===")
             await self._init_system()
-            
+
             # 2. Plugin Loading
             logger.info("\n=== Plugin Loading ===")
             await self._load_plugins()
-            
+
             # 3. Agent Initialization
             logger.info("\n=== Agent Initialization ===")
             await self._init_agents()
-            
+
             # 4. Memory Operations
             logger.info("\n=== Memory Operations ===")
             await self._demo_memory_ops()
-            
+
             # 5. Plugin Operations
             logger.info("\n=== Plugin Operations ===")
             await self._demo_plugin_ops()
-            
+
             # 6. System Monitoring
             logger.info("\n=== System Monitoring ===")
             await self._monitor_system()
-            
+
             # 7. Error Handling
             logger.info("\n=== Error Handling ===")
             await self._demo_error_handling()
-            
+
             # 8. System Status
             logger.info("\n=== System Status ===")
             await self._check_system_status()
-            
+
             logger.info("\nDemo completed successfully!")
-            
+
         except Exception as e:
             logger.error(f"Demo failed: {e}")
             raise
-    
+
     async def _init_system(self):
         """Initialize system components."""
         try:
             logger.info("Initializing system components...")
-            
+
             # Initialize core system
             success = await self.initializer.initialize()
             logger.info(f"System initialization: {'Success' if success else 'Failed'}")
-            
+
             # Load configuration
             config = self.initializer.get_config()
             logger.info(f"Loaded configuration: {len(config)} settings")
-            
+
             # Initialize thread manager
             self.thread_manager.initialize()
             logger.info("Thread manager initialized")
-            
+
             # Initialize memory system
             self.codex.initialize()
             logger.info("Memory system initialized")
-            
+
             # Initialize metacognition
             self.metacognition.initialize()
             logger.info("Metacognition system initialized")
-            
+
         except Exception as e:
             logger.error(f"System initialization failed: {e}")
             raise
-    
+
     async def _load_plugins(self):
         """Load and initialize plugins."""
         try:
             logger.info("Loading plugins...")
-            
+
             # Load all plugins
             plugin_count = self.plugin_loader.load_all_plugins()
             logger.info(f"Loaded {plugin_count} plugins")
-            
+
             # Verify plugin health
             for plugin_name, plugin in self.plugin_loader.plugins.items():
                 health = plugin.health_check()
                 logger.info(f"Plugin {plugin_name}: {health['status']}")
-            
+
         except Exception as e:
             logger.error(f"Plugin loading failed: {e}")
             raise
-    
+
     async def _init_agents(self):
         """Initialize system agents."""
         try:
             logger.info("Initializing agents...")
-            
+
             # Get agent status
             agents = self.thread_manager.get_agents()
             for agent in agents:
                 status = await agent.get_status()
                 logger.info(f"Agent {agent.name}: {status['status']}")
-            
+
         except Exception as e:
             logger.error(f"Agent initialization failed: {e}")
             raise
-    
+
     async def _demo_memory_ops(self):
         """Demonstrate memory operations."""
         try:
             logger.info("Demonstrating memory operations...")
-            
+
             # Store test memory
             memory_id = self.codex.store_memory(
                 content={
-                    'type': 'test_memory',
-                    'data': 'Hello, Threadspace!',
-                    'timestamp': datetime.utcnow().isoformat()
+                    "type": "test_memory",
+                    "data": "Hello, Threadspace!",
+                    "timestamp": datetime.utcnow().isoformat(),
                 },
-                source='demo',
-                tags=['test', 'demo'],
-                confidence=1.0
+                source="demo",
+                tags=["test", "demo"],
+                confidence=1.0,
             )
             logger.info(f"Stored memory: {memory_id}")
-            
+
             # Query memory
             memory = self.codex.query_memory(memory_id)
             logger.info(f"Retrieved memory: {memory}")
-            
+
             # Pattern analysis
             patterns = await self.codex.analyze_patterns()
             logger.info(f"Found {len(patterns)} patterns")
-            
+
         except Exception as e:
             logger.error(f"Memory operations failed: {e}")
             raise
-    
+
     async def _demo_plugin_ops(self):
         """Demonstrate plugin operations."""
         try:
             logger.info("Demonstrating plugin operations...")
-            
+
             # Get system diagnostics plugin
-            diagnostics = self.plugin_loader.get_plugin('system_diagnostics')
+            diagnostics = self.plugin_loader.get_plugin("system_diagnostics")
             if diagnostics:
                 # Run diagnostics
                 results = await diagnostics.run_diagnostics()
                 logger.info(f"Diagnostic results: {json.dumps(results, indent=2)}")
-            
+
             # Get pattern analyzer plugin
-            analyzer = self.plugin_loader.get_plugin('pattern_analyzer')
+            analyzer = self.plugin_loader.get_plugin("pattern_analyzer")
             if analyzer:
                 # Analyze patterns
                 patterns = await analyzer.analyze_patterns()
                 logger.info(f"Pattern analysis: {len(patterns)} patterns found")
-            
+
         except Exception as e:
             logger.error(f"Plugin operations failed: {e}")
             raise
-    
+
     async def _monitor_system(self):
         """Monitor system health and performance."""
         try:
             logger.info("Monitoring system...")
-            
+
             # Get thread status
             thread_info = self.thread_manager.get_thread_info()
             logger.info(f"Thread status: {thread_info}")
-            
+
             # Get memory usage
             memory_info = self.thread_manager.get_memory_info()
             logger.info(f"Memory usage: {memory_info}")
-            
+
             # Get performance metrics
             metrics = self.thread_manager.get_performance_metrics()
             logger.info(f"Performance metrics: {metrics}")
-            
+
         except Exception as e:
             logger.error(f"System monitoring failed: {e}")
             raise
-    
+
     async def _demo_error_handling(self):
         """Demonstrate error handling capabilities."""
         try:
             logger.info("Demonstrating error handling...")
-            
+
             # Simulate error condition
             try:
                 raise Exception("Test error")
             except Exception as e:
                 await self.metacognition.handle_error(
-                    error=e,
-                    context={'source': 'demo'}
+                    error=e, context={"source": "demo"}
                 )
                 logger.info("Error handled successfully")
-            
+
             # Check error recovery
             recovery_status = await self.metacognition.check_recovery_status()
             logger.info(f"Recovery status: {recovery_status}")
-            
+
         except Exception as e:
             logger.error(f"Error handling demo failed: {e}")
             raise
-    
+
     async def _check_system_status(self):
         """Check overall system status."""
         try:
             logger.info("Checking system status...")
-            
+
             # Get system health
             health = await self.initializer.health_check()
             logger.info(f"System health: {health['status']}")
-            
+
             # Get component status
             components = await self.initializer.get_component_status()
             logger.info("Component status:")
             for component, status in components.items():
                 logger.info(f"  {component}: {status['status']}")
-            
+
             # Get system metrics
             metrics = await self.initializer.get_system_metrics()
             logger.info(f"System metrics: {metrics}")
-            
+
         except Exception as e:
             logger.error(f"Status check failed: {e}")
             raise
 
+
 async def main():
     """Run the system demonstration."""
     try:
         demo = SystemDemo()
         await demo.run_demo()
     except Exception as e:
         logger.error(f"Demo failed: {e}")
         raise
 
+
 if __name__ == "__main__":
     # Run demo
     asyncio.run(main())
diff --git a/docs/INSTALLER.md b/docs/INSTALLER.md
new file mode 100644
index 0000000000000000000000000000000000000000..690f19a841891526b2c6cfcb39a264bd4bebe1e9
--- /dev/null
+++ b/docs/INSTALLER.md
@@ -0,0 +1,10 @@
+# Bundled Installer
+
+This project can be distributed as a single installer bundling ThreadSpace and required Ollama models.
+
+## Steps
+1. Package the `guardian_codex` application using `python -m build`.
+2. Download the necessary Ollama model files.
+3. Place the archives and wheel files into an `installer/` directory.
+4. Create an installer script that extracts the models and installs the wheel with `pip`.
+5. Distribute the installer script along with the packaged assets.
diff --git a/docs/RELEASE.md b/docs/RELEASE.md
new file mode 100644
index 0000000000000000000000000000000000000000..7bf00af18abfeb652dfbc8f251bbfd6bcfe22f8b
--- /dev/null
+++ b/docs/RELEASE.md
@@ -0,0 +1,15 @@
+# Release Process
+
+This project follows [Semantic Versioning](https://semver.org/).
+
+## Versioning Guidelines
+- Increment **MAJOR** for incompatible API changes.
+- Increment **MINOR** for backward compatible functionality.
+- Increment **PATCH** for backward compatible bug fixes.
+
+## Steps to Cut a Release
+1. Update version numbers in `pyproject.toml`, `setup.py`, and `CHANGELOG.md`.
+2. Commit changelog entries for the new version.
+3. Tag the commit with the version number, e.g. `v0.1.0`.
+4. Push the tag and create a GitHub Release using the tag.
+5. Attach built distributions to the release if applicable.
diff --git a/docs/SECURITY.md b/docs/SECURITY.md
new file mode 100644
index 0000000000000000000000000000000000000000..cd9905d2b8f354c656ec68696cef4f801e9304ed
--- /dev/null
+++ b/docs/SECURITY.md
@@ -0,0 +1,12 @@
+# Security Best Practices
+
+## Plugin Review Policy
+- All contributed plugins must undergo code review before inclusion.
+- Review focuses on dependency safety and adherence to `PluginBase`.
+
+## Secrets Management
+- Load sensitive configuration from a local `.env` file.
+- Never commit secrets to the repository.
+
+## Continuous Auditing
+- The CI workflow runs `pip-audit` to check for vulnerable dependencies.
diff --git a/docs/plugin_development.md b/docs/plugin_development.md
index 79d1ffe14ab8455d7e04a225b579d6dd218d2285..8127aa3adda3c7d60aa27aa2ca12fa5aee8a5304 100644
--- a/docs/plugin_development.md
+++ b/docs/plugin_development.md
@@ -100,50 +100,51 @@ def health_check() -> Dict[str, Any]:
     """Return plugin health status."""
     return {
         'status': 'healthy',
         'message': 'Plugin is running normally',
         'metrics': {
             'metric_1': 'value_1'
         }
     }
 ```
 
 ## 🔌 Plugin Interface
 
 ### Required Methods
 
 | Method | Description | Return Type |
 |--------|-------------|-------------|
 | `init_plugin()` | Initialize plugin | `bool` |
 | `get_metadata()` | Get plugin metadata | `Dict[str, Any]` |
 
 ### Optional Methods
 
 | Method | Description | Return Type |
 |--------|-------------|-------------|
 | `cleanup()` | Clean up resources | `bool` |
 | `health_check()` | Check plugin health | `Dict[str, Any]` |
+| `register_cli()` | Register CLI commands | `None` |
 
 ## ⚙️ Plugin Configuration
 
 ### Configuration File Structure
 
 ```json
 {
     "config": {
         "enabled": true,
         "interval": 300,
         "log_level": "INFO",
         "features": {
             "feature_1": true,
             "feature_2": false
         }
     }
 }
 ```
 
 ### Configuration Access
 
 ```python
 def get_config() -> Dict[str, Any]:
     """Get plugin configuration."""
     plugin_dir = Path(__file__).parent
diff --git a/guardian/logging_config.py b/guardian/logging_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..e751325b5cd0528846a54f03084877551814b73a
--- /dev/null
+++ b/guardian/logging_config.py
@@ -0,0 +1,9 @@
+"""Logging configuration using structlog."""
+
+import logging
+import structlog
+
+
+def configure_logging(level: int = logging.INFO) -> None:
+    logging.basicConfig(level=level, format="%(message)s")
+    structlog.configure(wrapper_class=structlog.make_filtering_bound_logger(level))
diff --git a/guardian/plugins/README.md b/guardian/plugins/README.md
index 81421e56be2aa0ecc51a66749485db389faa08d8..4c88a8f5e65fb9136cd64b7161e8afef1300911f 100644
--- a/guardian/plugins/README.md
+++ b/guardian/plugins/README.md
@@ -1,35 +1,33 @@
 # Guardian Plugin System
 
 This directory contains plugins that extend the Guardian system's functionality.
 
 ## Plugin Structure
 
 Each plugin should be contained in its own directory with the following structure:
 
 ```
 plugin_name/
 ├── plugin.json    # Plugin metadata and configuration
 ├── main.py        # Main plugin implementation
 └── tests/         # Plugin tests
     └── test_plugin.py
 ```
 
 ## Plugin Manifest
 
-The plugin.json file should contain:
+The plugin.json file should contain a manifest describing active and disabled plugins.
 
 ```json
 {
-<<<<<<< HEAD
-  "last_updated": "2025-06-26T03:54:26.170870",
-=======
   "last_updated": "2025-06-26T05:38:05.365713",
->>>>>>> 7f93d0c (✅ Add event-loop-safe global rate limiter system with Safe Mode config + test suite)
-  "active_plugins": {},
+  "active_plugins": {
+    "example": {"entry": "plugins/example/main.py"}
+  },
   "disabled_plugins": {}
 }
 ```
 
 ## Plugin Development
 
 See `docs/plugin_development.md` for detailed plugin development guidelines.
diff --git a/guardian/plugins/sandbox.py b/guardian/plugins/sandbox.py
new file mode 100644
index 0000000000000000000000000000000000000000..8e0226fce4c0d28ab717095f6d43c3be02079f85
--- /dev/null
+++ b/guardian/plugins/sandbox.py
@@ -0,0 +1,19 @@
+"""Simple plugin sandbox using subprocesses."""
+
+import subprocess
+from pathlib import Path
+from typing import List
+
+
+def run_plugin(path: Path, args: List[str]) -> subprocess.CompletedProcess:
+    """Execute a plugin in a subprocess.
+
+    Parameters
+    ----------
+    path: Path
+        Path to the plugin entry point.
+    args: List[str]
+        Arguments to pass to the plugin.
+    """
+    command = ["python", str(path)] + args
+    return subprocess.run(command, capture_output=True, text=True)
diff --git a/plugins/example/main.py b/plugins/example/main.py
new file mode 100644
index 0000000000000000000000000000000000000000..41305d9d4b3cc683327cd12f4a12ddf1723ac992
--- /dev/null
+++ b/plugins/example/main.py
@@ -0,0 +1,19 @@
+from guardian.plugins.plugin_base import PluginBase
+
+
+class ExamplePlugin(PluginBase):
+    """Minimal example plugin."""
+
+    @property
+    def name(self) -> str:
+        return "example"
+
+    @property
+    def version(self) -> str:
+        return "0.1.0"
+
+    def activate(self, core_services):
+        pass
+
+    def register_cli(self, cli):
+        pass
diff --git a/plugins/example/plugin.json b/plugins/example/plugin.json
new file mode 100644
index 0000000000000000000000000000000000000000..69e1ae8e7c03a5983534ca26cc60cac0a4cb24d6
--- /dev/null
+++ b/plugins/example/plugin.json
@@ -0,0 +1,5 @@
+{
+  "name": "example",
+  "version": "0.1.0",
+  "entry": "plugins/example/main.py"
+}
diff --git a/plugins/memory_analyzer/main.py b/plugins/memory_analyzer/main.py
index 6f891d607609e0d3c6d69420d03745e46fbcf6cf..8aa4bf40ee367347b44e30691000e07c8afa0623 100644
--- a/plugins/memory_analyzer/main.py
+++ b/plugins/memory_analyzer/main.py
@@ -1,243 +1,235 @@
 """
 Memory Analyzer Plugin
 -------------------
 Analyzes system memory patterns and provides insights on memory usage.
 Demonstrates proper plugin implementation and best practices.
 """
 
 import json
 import logging
 import threading
 import time
 from datetime import datetime, timedelta
 from pathlib import Path
 from typing import Any, Dict, List, Optional
+from guardian.logging_config import configure_logging
 
 # Configure logging
-logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
-)
+configure_logging()
 logger = logging.getLogger(__name__)
 
+
 class MemoryAnalyzer:
     """Core memory analysis functionality."""
-    
+
     def __init__(self, config: Dict[str, Any]):
         self.config = config
         self.metrics: Dict[str, Any] = {}
         self.patterns: List[Dict[str, Any]] = []
         self.last_analysis: Optional[datetime] = None
         self.running = False
         self.lock = threading.Lock()
         self.analysis_thread: Optional[threading.Thread] = None
-    
+
     def start(self) -> bool:
         """Start the analysis thread."""
         try:
             self.running = True
             self.analysis_thread = threading.Thread(
-                target=self._analysis_loop,
-                daemon=True
+                target=self._analysis_loop, daemon=True
             )
             self.analysis_thread.start()
             logger.info("Memory analyzer started")
             return True
         except Exception as e:
             logger.error(f"Failed to start memory analyzer: {e}")
             return False
-    
+
     def stop(self) -> bool:
         """Stop the analysis thread."""
         try:
             self.running = False
             if self.analysis_thread:
                 self.analysis_thread.join(timeout=5.0)
             logger.info("Memory analyzer stopped")
             return True
         except Exception as e:
             logger.error(f"Failed to stop memory analyzer: {e}")
             return False
-    
+
     def _analysis_loop(self) -> None:
         """Main analysis loop."""
         while self.running:
             try:
                 self._perform_analysis()
-                time.sleep(self.config['analysis_interval'])
+                time.sleep(self.config["analysis_interval"])
             except Exception as e:
                 logger.error(f"Analysis error: {e}")
                 time.sleep(10)  # Error backoff
-    
+
     def _perform_analysis(self) -> None:
         """Perform memory analysis."""
         with self.lock:
             current_time = datetime.utcnow()
-            
+
             # Collect memory metrics
             metrics = self._collect_metrics()
-            
+
             # Analyze patterns
             patterns = self._analyze_patterns(metrics)
-            
+
             # Update state
             self.metrics = metrics
             self.patterns.extend(patterns)
             self.last_analysis = current_time
-            
+
             # Cleanup old data
             self._cleanup_old_data()
-            
+
             # Check thresholds
             self._check_thresholds(metrics)
-    
+
     def _collect_metrics(self) -> Dict[str, Any]:
         """Collect current memory metrics."""
         # This is a simplified example - in practice, you would
         # collect real memory metrics from the system
         return {
-            'timestamp': datetime.utcnow().isoformat(),
-            'total_memory': 1000,
-            'used_memory': 500,
-            'memory_patterns': [
-                {'type': 'cyclic', 'confidence': 0.8},
-                {'type': 'growth', 'confidence': 0.6}
-            ]
+            "timestamp": datetime.utcnow().isoformat(),
+            "total_memory": 1000,
+            "used_memory": 500,
+            "memory_patterns": [
+                {"type": "cyclic", "confidence": 0.8},
+                {"type": "growth", "confidence": 0.6},
+            ],
         }
-    
-    def _analyze_patterns(
-        self,
-        metrics: Dict[str, Any]
-    ) -> List[Dict[str, Any]]:
+
+    def _analyze_patterns(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
         """Analyze memory usage patterns."""
         patterns = []
-        
+
         # Example pattern detection
-        usage_ratio = metrics['used_memory'] / metrics['total_memory']
+        usage_ratio = metrics["used_memory"] / metrics["total_memory"]
         if usage_ratio > 0.8:
-            patterns.append({
-                'type': 'high_usage',
-                'timestamp': datetime.utcnow().isoformat(),
-                'value': usage_ratio,
-                'confidence': 0.9
-            })
-        
+            patterns.append(
+                {
+                    "type": "high_usage",
+                    "timestamp": datetime.utcnow().isoformat(),
+                    "value": usage_ratio,
+                    "confidence": 0.9,
+                }
+            )
+
         return patterns
-    
+
     def _cleanup_old_data(self) -> None:
         """Remove data older than retention period."""
-        retention = timedelta(seconds=self.config['retention_period'])
+        retention = timedelta(seconds=self.config["retention_period"])
         current_time = datetime.utcnow()
-        
+
         self.patterns = [
-            p for p in self.patterns
-            if (current_time - datetime.fromisoformat(p['timestamp'])) <= retention
+            p
+            for p in self.patterns
+            if (current_time - datetime.fromisoformat(p["timestamp"])) <= retention
         ]
-    
+
     def _check_thresholds(self, metrics: Dict[str, Any]) -> None:
         """Check if metrics exceed configured thresholds."""
-        usage_ratio = metrics['used_memory'] / metrics['total_memory']
-        if usage_ratio > self.config['alert_threshold']:
+        usage_ratio = metrics["used_memory"] / metrics["total_memory"]
+        if usage_ratio > self.config["alert_threshold"]:
             logger.warning(
                 f"Memory usage ({usage_ratio:.2%}) exceeds threshold "
                 f"({self.config['alert_threshold']:.2%})"
             )
 
+
 # Global analyzer instance
 analyzer: Optional[MemoryAnalyzer] = None
 
+
 def init_plugin() -> bool:
     """Initialize the plugin."""
     try:
         # Load configuration
         plugin_dir = Path(__file__).parent
-        with open(plugin_dir / 'plugin.json', 'r') as f:
+        with open(plugin_dir / "plugin.json", "r") as f:
             config = json.load(f)
-        
+
         # Create and start analyzer
         global analyzer
-        analyzer = MemoryAnalyzer(config['config'])
+        analyzer = MemoryAnalyzer(config["config"])
         return analyzer.start()
-        
+
     except Exception as e:
         logger.error(f"Plugin initialization failed: {e}")
         return False
 
+
 def cleanup() -> bool:
     """Clean up plugin resources."""
     try:
         if analyzer:
             return analyzer.stop()
         return True
     except Exception as e:
         logger.error(f"Plugin cleanup failed: {e}")
         return False
 
+
 def get_metadata() -> Dict[str, Any]:
     """Return plugin metadata."""
     try:
         plugin_dir = Path(__file__).parent
-        with open(plugin_dir / 'plugin.json', 'r') as f:
+        with open(plugin_dir / "plugin.json", "r") as f:
             return json.load(f)
     except Exception as e:
         logger.error(f"Failed to load metadata: {e}")
         return {}
 
+
 def health_check() -> Dict[str, Any]:
     """Return plugin health status."""
     if not analyzer:
-        return {
-            'status': 'error',
-            'message': 'Analyzer not initialized'
-        }
-    
+        return {"status": "error", "message": "Analyzer not initialized"}
+
     try:
         with analyzer.lock:
             if not analyzer.last_analysis:
-                return {
-                    'status': 'warning',
-                    'message': 'No analysis performed yet'
-                }
-            
+                return {"status": "warning", "message": "No analysis performed yet"}
+
             age = datetime.utcnow() - analyzer.last_analysis
-            if age > timedelta(seconds=analyzer.config['analysis_interval'] * 2):
-                return {
-                    'status': 'warning',
-                    'message': f'Analysis is delayed: {age}'
-                }
-            
+            if age > timedelta(seconds=analyzer.config["analysis_interval"] * 2):
+                return {"status": "warning", "message": f"Analysis is delayed: {age}"}
+
             return {
-                'status': 'healthy',
-                'message': 'Analyzer is running normally',
-                'metrics': {
-                    'last_analysis': analyzer.last_analysis.isoformat(),
-                    'pattern_count': len(analyzer.patterns),
-                    'current_usage': analyzer.metrics.get('used_memory', 0) / 
-                                   analyzer.metrics.get('total_memory', 1)
-                }
+                "status": "healthy",
+                "message": "Analyzer is running normally",
+                "metrics": {
+                    "last_analysis": analyzer.last_analysis.isoformat(),
+                    "pattern_count": len(analyzer.patterns),
+                    "current_usage": analyzer.metrics.get("used_memory", 0)
+                    / analyzer.metrics.get("total_memory", 1),
+                },
             }
-            
+
     except Exception as e:
-        return {
-            'status': 'error',
-            'message': f'Health check failed: {e}'
-        }
+        return {"status": "error", "message": f"Health check failed: {e}"}
+
 
 # Example usage:
 if __name__ == "__main__":
     # Initialize plugin
     if init_plugin():
         print("Plugin initialized successfully")
-        
+
         # Wait for some analysis
         time.sleep(10)
-        
+
         # Check health
         health = health_check()
         print("\nHealth Status:")
         print(json.dumps(health, indent=2))
-        
+
         # Cleanup
         cleanup()
     else:
         print("Plugin initialization failed")
diff --git a/plugins/pattern_analyzer/main.py b/plugins/pattern_analyzer/main.py
index 95d5544da3030e487d596ab14c3529db09ce88e8..d4b73935507a45fa3dc2703aa6ac80bc52e1ecca 100644
--- a/plugins/pattern_analyzer/main.py
+++ b/plugins/pattern_analyzer/main.py
@@ -1,679 +1,614 @@
 """
 Pattern Analyzer Plugin
 --------------------
 Analyzes system behavior patterns and generates codex entries.
 Demonstrates integration with memory system and codex generation.
 """
 
 import json
 import logging
 import threading
 import time
 from datetime import datetime, timedelta
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Set, Tuple
+from guardian.logging_config import configure_logging
 
 from guardian.codex_awareness import CodexAwareness
 from guardian.metacognition import MetacognitionEngine
 
 # Configure logging
-logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
-)
+configure_logging()
 logger = logging.getLogger(__name__)
 
+
 class Pattern:
     """Represents a detected system behavior pattern."""
-    
+
     def __init__(
         self,
         pattern_type: str,
         signature: str,
         confidence: float,
         evidence: List[str],
-        metadata: Dict[str, Any]
+        metadata: Dict[str, Any],
     ):
         self.pattern_type = pattern_type
         self.signature = signature
         self.confidence = confidence
         self.evidence = evidence
         self.metadata = metadata
         self.timestamp = datetime.utcnow()
         self.verified = False
         self.codex_entry: Optional[str] = None
-    
+
     def to_dict(self) -> Dict[str, Any]:
         """Convert pattern to dictionary representation."""
         return {
-            'pattern_type': self.pattern_type,
-            'signature': self.signature,
-            'confidence': self.confidence,
-            'evidence': self.evidence,
-            'metadata': self.metadata,
-            'timestamp': self.timestamp.isoformat(),
-            'verified': self.verified,
-            'codex_entry': self.codex_entry
+            "pattern_type": self.pattern_type,
+            "signature": self.signature,
+            "confidence": self.confidence,
+            "evidence": self.evidence,
+            "metadata": self.metadata,
+            "timestamp": self.timestamp.isoformat(),
+            "verified": self.verified,
+            "codex_entry": self.codex_entry,
         }
 
+
 class PatternAnalyzer:
     """Core pattern analysis functionality."""
-    
+
     def __init__(self, config: Dict[str, Any]):
         self.config = config
         self.codex = CodexAwareness()
         self.metacognition = MetacognitionEngine()
         self.patterns: Dict[str, Pattern] = {}
         self.running = False
         self.analysis_thread: Optional[threading.Thread] = None
         self.last_analysis: Optional[datetime] = None
-    
+
     def start(self) -> bool:
         """Start the pattern analyzer."""
         try:
             self.running = True
             self.analysis_thread = threading.Thread(
-                target=self._analysis_loop,
-                daemon=True
+                target=self._analysis_loop, daemon=True
             )
             self.analysis_thread.start()
             logger.info("Pattern analyzer started")
             return True
         except Exception as e:
             logger.error(f"Failed to start pattern analyzer: {e}")
             return False
-    
+
     def stop(self) -> bool:
         """Stop the pattern analyzer."""
         try:
             self.running = False
             if self.analysis_thread:
                 self.analysis_thread.join(timeout=5.0)
             logger.info("Pattern analyzer stopped")
             return True
         except Exception as e:
             logger.error(f"Failed to stop pattern analyzer: {e}")
             return False
-    
+
     def _analysis_loop(self) -> None:
         """Main analysis loop."""
         while self.running:
             try:
                 self._analyze_patterns()
-                time.sleep(self.config['analysis_interval'])
+                time.sleep(self.config["analysis_interval"])
             except Exception as e:
                 logger.error(f"Analysis error: {e}")
                 time.sleep(10)  # Error backoff
-    
+
     def _analyze_patterns(self) -> None:
         """Perform pattern analysis."""
         try:
             # Query recent memory artifacts
             recent_memories = self.codex.query_memory(
                 query="timestamp:[now-1h TO now]",
-                min_confidence=self.config['min_confidence']
+                min_confidence=self.config["min_confidence"],
             )
-            
+
             # Analyze different pattern types
-            for pattern_type in self.config['pattern_types']:
-                patterns = self._analyze_pattern_type(
-                    pattern_type,
-                    recent_memories
-                )
-                
+            for pattern_type in self.config["pattern_types"]:
+                patterns = self._analyze_pattern_type(pattern_type, recent_memories)
+
                 # Generate codex entries for new patterns
                 for pattern in patterns:
                     if pattern.signature not in self.patterns:
                         self._generate_codex_entry(pattern)
                         self.patterns[pattern.signature] = pattern
-            
+
             # Clean up old patterns
             self._cleanup_patterns()
-            
+
             self.last_analysis = datetime.utcnow()
-            
+
         except Exception as e:
             logger.error(f"Pattern analysis failed: {e}")
-    
+
     def _analyze_pattern_type(
-        self,
-        pattern_type: str,
-        memories: List[Any]
+        self, pattern_type: str, memories: List[Any]
     ) -> List[Pattern]:
         """Analyze specific type of patterns."""
         patterns: List[Pattern] = []
-        
+
         if pattern_type == "behavioral":
-            patterns.extend(
-                self._analyze_behavioral_patterns(memories)
-            )
+            patterns.extend(self._analyze_behavioral_patterns(memories))
         elif pattern_type == "temporal":
-            patterns.extend(
-                self._analyze_temporal_patterns(memories)
-            )
+            patterns.extend(self._analyze_temporal_patterns(memories))
         elif pattern_type == "structural":
-            patterns.extend(
-                self._analyze_structural_patterns(memories)
-            )
+            patterns.extend(self._analyze_structural_patterns(memories))
         elif pattern_type == "relational":
-            patterns.extend(
-                self._analyze_relational_patterns(memories)
-            )
-        
+            patterns.extend(self._analyze_relational_patterns(memories))
+
         return patterns
-    
-    def _analyze_behavioral_patterns(
-        self,
-        memories: List[Any]
-    ) -> List[Pattern]:
+
+    def _analyze_behavioral_patterns(self, memories: List[Any]) -> List[Pattern]:
         """Analyze behavioral patterns in system operations."""
         patterns: List[Pattern] = []
-        
+
         # Group memories by operation type
         operations: Dict[str, List[Any]] = {}
         for memory in memories:
-            if hasattr(memory, 'content'):
-                op_type = memory.content.get('operation_type')
+            if hasattr(memory, "content"):
+                op_type = memory.content.get("operation_type")
                 if op_type:
                     operations.setdefault(op_type, []).append(memory)
-        
+
         # Analyze operation sequences
         for op_type, op_memories in operations.items():
             if len(op_memories) >= 3:  # Minimum sequence length
                 # Look for repeated sequences
                 sequences = self._find_sequences(op_memories)
-                
+
                 for seq in sequences:
                     pattern = Pattern(
                         pattern_type="behavioral",
                         signature=f"behavior_{op_type}_{hash(str(seq))}",
                         confidence=self._calculate_sequence_confidence(seq),
                         evidence=[m.id for m in seq],
                         metadata={
-                            'operation_type': op_type,
-                            'sequence_length': len(seq),
-                            'frequency': self._calculate_sequence_frequency(
-                                seq,
-                                op_memories
-                            )
-                        }
+                            "operation_type": op_type,
+                            "sequence_length": len(seq),
+                            "frequency": self._calculate_sequence_frequency(
+                                seq, op_memories
+                            ),
+                        },
                     )
                     patterns.append(pattern)
-        
+
         return patterns
-    
-    def _analyze_temporal_patterns(
-        self,
-        memories: List[Any]
-    ) -> List[Pattern]:
+
+    def _analyze_temporal_patterns(self, memories: List[Any]) -> List[Pattern]:
         """Analyze temporal patterns in system events."""
         patterns: List[Pattern] = []
-        
+
         # Group memories by time intervals
         intervals = self._group_by_intervals(memories, timedelta(minutes=5))
-        
+
         # Analyze interval patterns
         for interval, interval_memories in intervals.items():
             if len(interval_memories) >= 3:
                 # Look for periodic events
                 periodic = self._find_periodic_events(interval_memories)
-                
+
                 for period, events in periodic.items():
                     pattern = Pattern(
                         pattern_type="temporal",
                         signature=f"temporal_{interval}_{period}",
                         confidence=self._calculate_periodic_confidence(events),
                         evidence=[e.id for e in events],
                         metadata={
-                            'interval': str(interval),
-                            'period': period,
-                            'event_count': len(events)
-                        }
+                            "interval": str(interval),
+                            "period": period,
+                            "event_count": len(events),
+                        },
                     )
                     patterns.append(pattern)
-        
+
         return patterns
-    
-    def _analyze_structural_patterns(
-        self,
-        memories: List[Any]
-    ) -> List[Pattern]:
+
+    def _analyze_structural_patterns(self, memories: List[Any]) -> List[Pattern]:
         """Analyze structural patterns in system components."""
         patterns: List[Pattern] = []
-        
+
         # Build component dependency graph
         dependencies = self._build_dependency_graph(memories)
-        
+
         # Find structural patterns
         structural_patterns = self._find_structural_patterns(dependencies)
-        
+
         for pattern_type, components in structural_patterns.items():
             pattern = Pattern(
                 pattern_type="structural",
                 signature=f"structure_{pattern_type}_{hash(str(components))}",
                 confidence=self._calculate_structural_confidence(components),
                 evidence=[str(c) for c in components],
                 metadata={
-                    'pattern_type': pattern_type,
-                    'component_count': len(components),
-                    'dependencies': dependencies
-                }
+                    "pattern_type": pattern_type,
+                    "component_count": len(components),
+                    "dependencies": dependencies,
+                },
             )
             patterns.append(pattern)
-        
+
         return patterns
-    
-    def _analyze_relational_patterns(
-        self,
-        memories: List[Any]
-    ) -> List[Pattern]:
+
+    def _analyze_relational_patterns(self, memories: List[Any]) -> List[Pattern]:
         """Analyze relational patterns between system elements."""
         patterns: List[Pattern] = []
-        
+
         # Build relationship graph
         relationships = self._build_relationship_graph(memories)
-        
+
         # Find clusters and patterns
         clusters = self._find_relationship_clusters(relationships)
-        
+
         for cluster_type, elements in clusters.items():
             pattern = Pattern(
                 pattern_type="relational",
                 signature=f"relation_{cluster_type}_{hash(str(elements))}",
                 confidence=self._calculate_relational_confidence(elements),
                 evidence=[str(e) for e in elements],
                 metadata={
-                    'cluster_type': cluster_type,
-                    'element_count': len(elements),
-                    'relationship_strength': self._calculate_relationship_strength(
-                        elements,
-                        relationships
-                    )
-                }
+                    "cluster_type": cluster_type,
+                    "element_count": len(elements),
+                    "relationship_strength": self._calculate_relationship_strength(
+                        elements, relationships
+                    ),
+                },
             )
             patterns.append(pattern)
-        
+
         return patterns
-    
-    def _find_sequences(
-        self,
-        memories: List[Any]
-    ) -> List[List[Any]]:
+
+    def _find_sequences(self, memories: List[Any]) -> List[List[Any]]:
         """Find repeated sequences in memories."""
         sequences: List[List[Any]] = []
         min_length = 3
-        
+
         for i in range(len(memories) - min_length + 1):
             for j in range(i + min_length, len(memories) + 1):
                 sequence = memories[i:j]
                 # Check if sequence repeats
                 if self._is_repeated_sequence(sequence, memories):
                     sequences.append(sequence)
-        
+
         return sequences
-    
-    def _is_repeated_sequence(
-        self,
-        sequence: List[Any],
-        memories: List[Any]
-    ) -> bool:
+
+    def _is_repeated_sequence(self, sequence: List[Any], memories: List[Any]) -> bool:
         """Check if a sequence repeats in memories."""
         seq_str = self._sequence_to_string(sequence)
         mem_str = self._sequence_to_string(memories)
-        
+
         # Count occurrences
         return mem_str.count(seq_str) > 1
-    
+
     def _sequence_to_string(self, sequence: List[Any]) -> str:
         """Convert sequence to string representation."""
-        return ','.join(
-            str(getattr(m, 'content', {}).get('operation_type', ''))
-            for m in sequence
+        return ",".join(
+            str(getattr(m, "content", {}).get("operation_type", "")) for m in sequence
         )
-    
-    def _calculate_sequence_confidence(
-        self,
-        sequence: List[Any]
-    ) -> float:
+
+    def _calculate_sequence_confidence(self, sequence: List[Any]) -> float:
         """Calculate confidence in a behavioral sequence."""
         if not sequence:
             return 0.0
-        
+
         # Consider sequence length
         length_factor = min(len(sequence) / 10.0, 1.0)
-        
+
         # Consider memory confidence
-        confidence_avg = sum(
-            getattr(m, 'confidence', 0.0) for m in sequence
-        ) / len(sequence)
-        
+        confidence_avg = sum(getattr(m, "confidence", 0.0) for m in sequence) / len(
+            sequence
+        )
+
         return (length_factor + confidence_avg) / 2.0
-    
+
     def _calculate_sequence_frequency(
-        self,
-        sequence: List[Any],
-        memories: List[Any]
+        self, sequence: List[Any], memories: List[Any]
     ) -> float:
         """Calculate frequency of a sequence in memories."""
         seq_str = self._sequence_to_string(sequence)
         mem_str = self._sequence_to_string(memories)
-        
+
         count = mem_str.count(seq_str)
         max_possible = len(memories) - len(sequence) + 1
-        
+
         return count / max_possible if max_possible > 0 else 0.0
-    
+
     def _group_by_intervals(
-        self,
-        memories: List[Any],
-        interval: timedelta
+        self, memories: List[Any], interval: timedelta
     ) -> Dict[str, List[Any]]:
         """Group memories by time intervals."""
         intervals: Dict[str, List[Any]] = {}
-        
+
         for memory in memories:
-            if hasattr(memory, 'timestamp'):
+            if hasattr(memory, "timestamp"):
                 interval_start = memory.timestamp.replace(
-                    minute=memory.timestamp.minute // 5 * 5,
-                    second=0,
-                    microsecond=0
+                    minute=memory.timestamp.minute // 5 * 5, second=0, microsecond=0
                 )
                 interval_key = interval_start.isoformat()
                 intervals.setdefault(interval_key, []).append(memory)
-        
+
         return intervals
-    
-    def _find_periodic_events(
-        self,
-        memories: List[Any]
-    ) -> Dict[str, List[Any]]:
+
+    def _find_periodic_events(self, memories: List[Any]) -> Dict[str, List[Any]]:
         """Find periodic events in memories."""
         periodic: Dict[str, List[Any]] = {}
-        
+
         # Group by event type
         events: Dict[str, List[Any]] = {}
         for memory in memories:
-            if hasattr(memory, 'content'):
-                event_type = memory.content.get('event_type')
+            if hasattr(memory, "content"):
+                event_type = memory.content.get("event_type")
                 if event_type:
                     events.setdefault(event_type, []).append(memory)
-        
+
         # Find periodic patterns
         for event_type, event_memories in events.items():
             if self._is_periodic(event_memories):
                 period = self._calculate_period(event_memories)
                 periodic[f"{event_type}_{period}"] = event_memories
-        
+
         return periodic
-    
+
     def _is_periodic(self, memories: List[Any]) -> bool:
         """Check if events show periodic behavior."""
         if len(memories) < 3:
             return False
-        
+
         # Calculate intervals between events
         intervals = []
         for i in range(1, len(memories)):
-            if hasattr(memories[i], 'timestamp') and hasattr(memories[i-1], 'timestamp'):
+            if hasattr(memories[i], "timestamp") and hasattr(
+                memories[i - 1], "timestamp"
+            ):
                 interval = (
-                    memories[i].timestamp - memories[i-1].timestamp
+                    memories[i].timestamp - memories[i - 1].timestamp
                 ).total_seconds()
                 intervals.append(interval)
-        
+
         if not intervals:
             return False
-        
+
         # Check if intervals are consistent
         avg_interval = sum(intervals) / len(intervals)
-        variance = sum(
-            (i - avg_interval) ** 2 for i in intervals
-        ) / len(intervals)
-        
+        variance = sum((i - avg_interval) ** 2 for i in intervals) / len(intervals)
+
         # Low variance indicates periodicity
         return variance < (avg_interval * 0.2)
-    
+
     def _calculate_period(self, memories: List[Any]) -> str:
         """Calculate the period of periodic events."""
         intervals = []
         for i in range(1, len(memories)):
-            if hasattr(memories[i], 'timestamp') and hasattr(memories[i-1], 'timestamp'):
+            if hasattr(memories[i], "timestamp") and hasattr(
+                memories[i - 1], "timestamp"
+            ):
                 interval = (
-                    memories[i].timestamp - memories[i-1].timestamp
+                    memories[i].timestamp - memories[i - 1].timestamp
                 ).total_seconds()
                 intervals.append(interval)
-        
+
         if not intervals:
             return "unknown"
-        
+
         avg_interval = sum(intervals) / len(intervals)
-        
+
         # Convert to human-readable period
         if avg_interval < 60:
             return f"{int(avg_interval)}s"
         elif avg_interval < 3600:
             return f"{int(avg_interval/60)}m"
         else:
             return f"{int(avg_interval/3600)}h"
-    
+
     def _generate_codex_entry(self, pattern: Pattern) -> None:
         """Generate codex entry for a pattern."""
         try:
             entry_content = {
-                'type': 'pattern_codex',
-                'pattern': pattern.to_dict(),
-                'analysis': self._generate_pattern_analysis(pattern),
-                'implications': self._generate_pattern_implications(pattern),
-                'recommendations': self._generate_pattern_recommendations(pattern)
+                "type": "pattern_codex",
+                "pattern": pattern.to_dict(),
+                "analysis": self._generate_pattern_analysis(pattern),
+                "implications": self._generate_pattern_implications(pattern),
+                "recommendations": self._generate_pattern_recommendations(pattern),
             }
-            
+
             # Store in codex
             pattern.codex_entry = self.codex.store_memory(
                 content=entry_content,
-                source='pattern_analyzer',
-                tags=['pattern', pattern.pattern_type, 'codex'],
-                confidence=pattern.confidence
+                source="pattern_analyzer",
+                tags=["pattern", pattern.pattern_type, "codex"],
+                confidence=pattern.confidence,
             )
-            
+
         except Exception as e:
             logger.error(f"Failed to generate codex entry: {e}")
-    
-    def _generate_pattern_analysis(
-        self,
-        pattern: Pattern
-    ) -> Dict[str, Any]:
+
+    def _generate_pattern_analysis(self, pattern: Pattern) -> Dict[str, Any]:
         """Generate analysis of pattern characteristics."""
         return {
-            'characteristics': {
-                'frequency': self._analyze_pattern_frequency(pattern),
-                'stability': self._analyze_pattern_stability(pattern),
-                'impact': self._analyze_pattern_impact(pattern)
+            "characteristics": {
+                "frequency": self._analyze_pattern_frequency(pattern),
+                "stability": self._analyze_pattern_stability(pattern),
+                "impact": self._analyze_pattern_impact(pattern),
+            },
+            "context": {
+                "system_state": self._get_system_state_context(pattern),
+                "related_patterns": self._find_related_patterns(pattern),
             },
-            'context': {
-                'system_state': self._get_system_state_context(pattern),
-                'related_patterns': self._find_related_patterns(pattern)
-            }
         }
-    
-    def _generate_pattern_implications(
-        self,
-        pattern: Pattern
-    ) -> List[Dict[str, Any]]:
+
+    def _generate_pattern_implications(self, pattern: Pattern) -> List[Dict[str, Any]]:
         """Generate implications of the pattern."""
         implications = []
-        
+
         # Performance implications
         perf_impact = self._analyze_performance_impact(pattern)
         if perf_impact:
-            implications.append({
-                'type': 'performance',
-                'description': perf_impact['description'],
-                'severity': perf_impact['severity']
-            })
-        
+            implications.append(
+                {
+                    "type": "performance",
+                    "description": perf_impact["description"],
+                    "severity": perf_impact["severity"],
+                }
+            )
+
         # Resource implications
         resource_impact = self._analyze_resource_impact(pattern)
         if resource_impact:
-            implications.append({
-                'type': 'resource',
-                'description': resource_impact['description'],
-                'severity': resource_impact['severity']
-            })
-        
+            implications.append(
+                {
+                    "type": "resource",
+                    "description": resource_impact["description"],
+                    "severity": resource_impact["severity"],
+                }
+            )
+
         # Stability implications
         stability_impact = self._analyze_stability_impact(pattern)
         if stability_impact:
-            implications.append({
-                'type': 'stability',
-                'description': stability_impact['description'],
-                'severity': stability_impact['severity']
-            })
-        
+            implications.append(
+                {
+                    "type": "stability",
+                    "description": stability_impact["description"],
+                    "severity": stability_impact["severity"],
+                }
+            )
+
         return implications
-    
+
     def _generate_pattern_recommendations(
-        self,
-        pattern: Pattern
+        self, pattern: Pattern
     ) -> List[Dict[str, Any]]:
         """Generate recommendations based on pattern analysis."""
         recommendations = []
-        
+
         # Performance optimization recommendations
         if pattern.pattern_type == "behavioral":
-            recommendations.extend(
-                self._generate_behavioral_recommendations(pattern)
-            )
-        
+            recommendations.extend(self._generate_behavioral_recommendations(pattern))
+
         # Resource management recommendations
         elif pattern.pattern_type == "structural":
-            recommendations.extend(
-                self._generate_structural_recommendations(pattern)
-            )
-        
+            recommendations.extend(self._generate_structural_recommendations(pattern))
+
         # Monitoring recommendations
-        recommendations.extend(
-            self._generate_monitoring_recommendations(pattern)
-        )
-        
+        recommendations.extend(self._generate_monitoring_recommendations(pattern))
+
         return recommendations
-    
+
     def _cleanup_patterns(self) -> None:
         """Clean up old or invalid patterns."""
         current_time = datetime.utcnow()
-        
+
         # Remove patterns older than 24 hours
         self.patterns = {
             sig: pattern
             for sig, pattern in self.patterns.items()
             if (current_time - pattern.timestamp) < timedelta(hours=24)
         }
-        
+
         # Limit total number of patterns
-        if len(self.patterns) > self.config['max_patterns']:
+        if len(self.patterns) > self.config["max_patterns"]:
             # Sort by confidence and keep top patterns
             sorted_patterns = sorted(
-                self.patterns.items(),
-                key=lambda x: x[1].confidence,
-                reverse=True
-            )
-            self.patterns = dict(
-                sorted_patterns[:self.config['max_patterns']]
+                self.patterns.items(), key=lambda x: x[1].confidence, reverse=True
             )
+            self.patterns = dict(sorted_patterns[: self.config["max_patterns"]])
+
 
 # Global analyzer instance
 analyzer: Optional[PatternAnalyzer] = None
 
+
 def init_plugin() -> bool:
     """Initialize the plugin."""
     try:
         # Load configuration
         plugin_dir = Path(__file__).parent
-        with open(plugin_dir / 'plugin.json', 'r') as f:
+        with open(plugin_dir / "plugin.json", "r") as f:
             config = json.load(f)
-        
+
         # Create and start analyzer
         global analyzer
-        analyzer = PatternAnalyzer(config['config'])
+        analyzer = PatternAnalyzer(config["config"])
         return analyzer.start()
-        
+
     except Exception as e:
         logger.error(f"Plugin initialization failed: {e}")
         return False
 
+
 def cleanup() -> bool:
     """Clean up plugin resources."""
     try:
         if analyzer:
             return analyzer.stop()
         return True
     except Exception as e:
         logger.error(f"Plugin cleanup failed: {e}")
         return False
 
+
 def get_metadata() -> Dict[str, Any]:
     """Return plugin metadata."""
     try:
         plugin_dir = Path(__file__).parent
-        with open(plugin_dir / 'plugin.json', 'r') as f:
+        with open(plugin_dir / "plugin.json", "r") as f:
             return json.load(f)
     except Exception as e:
         logger.error(f"Failed to load metadata: {e}")
         return {}
 
+
 def health_check() -> Dict[str, Any]:
     """Return plugin health status."""
     if not analyzer:
-        return {
-            'status': 'error',
-            'message': 'Analyzer not initialized'
-        }
-    
+        return {"status": "error", "message": "Analyzer not initialized"}
+
     try:
         if not analyzer.last_analysis:
-            return {
-                'status': 'warning',
-                'message': 'No analysis performed yet'
-            }
-        
+            return {"status": "warning", "message": "No analysis performed yet"}
+
         age = datetime.utcnow() - analyzer.last_analysis
-        if age > timedelta(
-            seconds=analyzer.config['analysis_interval'] * 2
-        ):
-            return {
-                'status': 'warning',
-                'message': f'Analysis is delayed: {age}'
-            }
-        
+        if age > timedelta(seconds=analyzer.config["analysis_interval"] * 2):
+            return {"status": "warning", "message": f"Analysis is delayed: {age}"}
+
         return {
-            'status': 'healthy',
-            'message': 'Pattern analyzer is running normally',
-            'metrics': {
-                'last_analysis': analyzer.last_analysis.isoformat(),
-                'pattern_count': len(analyzer.patterns),
-                'types_analyzed': analyzer.config['pattern_types']
-            }
+            "status": "healthy",
+            "message": "Pattern analyzer is running normally",
+            "metrics": {
+                "last_analysis": analyzer.last_analysis.isoformat(),
+                "pattern_count": len(analyzer.patterns),
+                "types_analyzed": analyzer.config["pattern_types"],
+            },
         }
-        
+
     except Exception as e:
-        return {
-            'status': 'error',
-            'message': f'Health check failed: {e}'
-        }
+        return {"status": "error", "message": f"Health check failed: {e}"}
+
 
 # Example usage:
 if __name__ == "__main__":
     # Initialize plugin
     if init_plugin():
         print("Plugin initialized successfully")
-        
+
         # Wait for some analysis
         time.sleep(10)
-        
+
         # Check health
         health = health_check()
         print("\nHealth Status:")
         print(json.dumps(health, indent=2))
-        
+
         # Cleanup
         cleanup()
     else:
         print("Plugin initialization failed")
diff --git a/plugins/system_diagnostics/main.py b/plugins/system_diagnostics/main.py
index 27455ca9d6815c06fc4cf90919598e58fd4bb105..d4ced37357aca0d8d7fe9b4f96088c209f5a2bf0 100644
--- a/plugins/system_diagnostics/main.py
+++ b/plugins/system_diagnostics/main.py
@@ -1,838 +1,822 @@
 """
 System Diagnostics Plugin
 ------------------------
 Advanced system monitoring and diagnostics with comprehensive error handling
 and core system communication.
 """
 
 import asyncio
 import json
 import logging
 import threading
 import time
 from datetime import datetime, timedelta
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Set, Tuple, Union
 
 from guardian.codex_awareness import CodexAwareness
 from guardian.metacognition import MetacognitionEngine
 from guardian.threads.thread_manager import ThreadManager
+from guardian.logging_config import configure_logging
 
 # Configure logging
-logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
-)
+configure_logging()
 logger = logging.getLogger(__name__)
 
+
 class DiagnosticResult:
     """Represents a diagnostic check result."""
-    
+
     def __init__(
         self,
         check_type: str,
         status: str,
         value: Any,
         threshold: Optional[float] = None,
-        metadata: Optional[Dict[str, Any]] = None
+        metadata: Optional[Dict[str, Any]] = None,
     ):
         self.check_type = check_type
         self.status = status
         self.value = value
         self.threshold = threshold
         self.metadata = metadata or {}
         self.timestamp = datetime.utcnow()
         self.anomaly_score = self._calculate_anomaly_score()
-    
+
     def to_dict(self) -> Dict[str, Any]:
         """Convert result to dictionary representation."""
         return {
-            'check_type': self.check_type,
-            'status': self.status,
-            'value': self.value,
-            'threshold': self.threshold,
-            'metadata': self.metadata,
-            'timestamp': self.timestamp.isoformat(),
-            'anomaly_score': self.anomaly_score
+            "check_type": self.check_type,
+            "status": self.status,
+            "value": self.value,
+            "threshold": self.threshold,
+            "metadata": self.metadata,
+            "timestamp": self.timestamp.isoformat(),
+            "anomaly_score": self.anomaly_score,
         }
-    
+
     def _calculate_anomaly_score(self) -> float:
         """Calculate anomaly score based on value and threshold."""
         if self.threshold is None:
             return 0.0
-        
+
         try:
             if isinstance(self.value, (int, float)):
                 return abs(self.value - self.threshold) / self.threshold
             return 0.0
         except Exception:
             return 0.0
 
+
 class SystemDiagnostics:
     """Core system diagnostics functionality."""
-    
+
     def __init__(self, config: Dict[str, Any]):
         self.config = config
         self.codex = CodexAwareness()
         self.metacognition = MetacognitionEngine()
         self.thread_manager = ThreadManager()
-        
+
         self.running = False
         self.diagnostic_thread: Optional[threading.Thread] = None
         self.last_check: Optional[datetime] = None
         self.check_results: List[DiagnosticResult] = []
         self.error_count: Dict[str, int] = {}
         self.recovery_in_progress = False
-        
+
         # Initialize monitors
         self.monitors = self._initialize_monitors()
-    
+
     def _initialize_monitors(self) -> Dict[str, Any]:
         """Initialize monitoring components."""
         monitors = {}
-        
-        if self.config['monitors']['memory']:
-            monitors['memory'] = self.MemoryMonitor(self)
-        
-        if self.config['monitors']['threads']:
-            monitors['threads'] = self.ThreadMonitor(self)
-        
-        if self.config['monitors']['plugins']:
-            monitors['plugins'] = self.PluginMonitor(self)
-        
-        if self.config['monitors']['agents']:
-            monitors['agents'] = self.AgentMonitor(self)
-        
-        if self.config['monitors']['performance']:
-            monitors['performance'] = self.PerformanceMonitor(self)
-        
-        if self.config['monitors']['errors']:
-            monitors['errors'] = self.ErrorMonitor(self)
-        
+
+        if self.config["monitors"]["memory"]:
+            monitors["memory"] = self.MemoryMonitor(self)
+
+        if self.config["monitors"]["threads"]:
+            monitors["threads"] = self.ThreadMonitor(self)
+
+        if self.config["monitors"]["plugins"]:
+            monitors["plugins"] = self.PluginMonitor(self)
+
+        if self.config["monitors"]["agents"]:
+            monitors["agents"] = self.AgentMonitor(self)
+
+        if self.config["monitors"]["performance"]:
+            monitors["performance"] = self.PerformanceMonitor(self)
+
+        if self.config["monitors"]["errors"]:
+            monitors["errors"] = self.ErrorMonitor(self)
+
         return monitors
-    
+
     class BaseMonitor:
         """Base class for monitors."""
-        
-        def __init__(self, diagnostics: 'SystemDiagnostics'):
+
+        def __init__(self, diagnostics: "SystemDiagnostics"):
             self.diagnostics = diagnostics
             self.history: List[DiagnosticResult] = []
-        
+
         async def check(self) -> DiagnosticResult:
             """Perform monitoring check."""
             raise NotImplementedError
-        
+
         def _trim_history(self) -> None:
             """Trim history to configured size."""
-            max_history = self.diagnostics.config['max_history']
+            max_history = self.diagnostics.config["max_history"]
             if len(self.history) > max_history:
                 self.history = self.history[-max_history:]
-    
+
     class MemoryMonitor(BaseMonitor):
         """Monitors system memory usage."""
-        
+
         async def check(self) -> DiagnosticResult:
             try:
                 # Get memory usage from core system
                 memory_info = self.diagnostics.thread_manager.get_memory_info()
-                
-                usage = memory_info['usage_percent']
+
+                usage = memory_info["usage_percent"]
                 threshold = 80.0  # 80% memory usage threshold
-                
-                status = 'healthy' if usage < threshold else 'warning'
-                
+
+                status = "healthy" if usage < threshold else "warning"
+
                 result = DiagnosticResult(
-                    check_type='memory',
+                    check_type="memory",
                     status=status,
                     value=usage,
                     threshold=threshold,
-                    metadata=memory_info
+                    metadata=memory_info,
                 )
-                
+
                 self.history.append(result)
                 self._trim_history()
-                
+
                 return result
-                
+
             except Exception as e:
                 logger.error(f"Memory check failed: {e}")
                 return DiagnosticResult(
-                    check_type='memory',
-                    status='error',
+                    check_type="memory",
+                    status="error",
                     value=None,
-                    metadata={'error': str(e)}
+                    metadata={"error": str(e)},
                 )
-    
+
     class ThreadMonitor(BaseMonitor):
         """Monitors thread health and performance."""
-        
+
         async def check(self) -> DiagnosticResult:
             try:
                 thread_info = self.diagnostics.thread_manager.get_thread_info()
-                
-                active_threads = thread_info['active_count']
-                dead_threads = thread_info['dead_count']
-                threshold = self.diagnostics.config.get('max_dead_threads', 5)
-                
-                status = 'healthy' if dead_threads < threshold else 'warning'
-                
+
+                active_threads = thread_info["active_count"]
+                dead_threads = thread_info["dead_count"]
+                threshold = self.diagnostics.config.get("max_dead_threads", 5)
+
+                status = "healthy" if dead_threads < threshold else "warning"
+
                 result = DiagnosticResult(
-                    check_type='threads',
+                    check_type="threads",
                     status=status,
                     value=dead_threads,
                     threshold=threshold,
                     metadata={
-                        'active_threads': active_threads,
-                        'dead_threads': dead_threads,
-                        'thread_info': thread_info
-                    }
+                        "active_threads": active_threads,
+                        "dead_threads": dead_threads,
+                        "thread_info": thread_info,
+                    },
                 )
-                
+
                 self.history.append(result)
                 self._trim_history()
-                
+
                 return result
-                
+
             except Exception as e:
                 logger.error(f"Thread check failed: {e}")
                 return DiagnosticResult(
-                    check_type='threads',
-                    status='error',
+                    check_type="threads",
+                    status="error",
                     value=None,
-                    metadata={'error': str(e)}
+                    metadata={"error": str(e)},
                 )
-    
+
     class PluginMonitor(BaseMonitor):
         """Monitors plugin health and status."""
-        
+
         async def check(self) -> DiagnosticResult:
             try:
                 plugin_info = await self.diagnostics._check_plugins()
-                
-                unhealthy_plugins = len([
-                    p for p in plugin_info['plugins']
-                    if p['status'] != 'healthy'
-                ])
-                threshold = self.diagnostics.config.get(
-                    'max_unhealthy_plugins',
-                    2
+
+                unhealthy_plugins = len(
+                    [p for p in plugin_info["plugins"] if p["status"] != "healthy"]
                 )
-                
-                status = 'healthy' if unhealthy_plugins < threshold else 'warning'
-                
+                threshold = self.diagnostics.config.get("max_unhealthy_plugins", 2)
+
+                status = "healthy" if unhealthy_plugins < threshold else "warning"
+
                 result = DiagnosticResult(
-                    check_type='plugins',
+                    check_type="plugins",
                     status=status,
                     value=unhealthy_plugins,
                     threshold=threshold,
-                    metadata=plugin_info
+                    metadata=plugin_info,
                 )
-                
+
                 self.history.append(result)
                 self._trim_history()
-                
+
                 return result
-                
+
             except Exception as e:
                 logger.error(f"Plugin check failed: {e}")
                 return DiagnosticResult(
-                    check_type='plugins',
-                    status='error',
+                    check_type="plugins",
+                    status="error",
                     value=None,
-                    metadata={'error': str(e)}
+                    metadata={"error": str(e)},
                 )
-    
+
     class AgentMonitor(BaseMonitor):
         """Monitors agent health and performance."""
-        
+
         async def check(self) -> DiagnosticResult:
             try:
                 agent_info = await self.diagnostics._check_agents()
-                
-                unhealthy_agents = len([
-                    a for a in agent_info['agents']
-                    if a['status'] != 'healthy'
-                ])
+
+                unhealthy_agents = len(
+                    [a for a in agent_info["agents"] if a["status"] != "healthy"]
+                )
                 threshold = 0  # No unhealthy agents allowed
-                
-                status = 'healthy' if unhealthy_agents == 0 else 'critical'
-                
+
+                status = "healthy" if unhealthy_agents == 0 else "critical"
+
                 result = DiagnosticResult(
-                    check_type='agents',
+                    check_type="agents",
                     status=status,
                     value=unhealthy_agents,
                     threshold=threshold,
-                    metadata=agent_info
+                    metadata=agent_info,
                 )
-                
+
                 self.history.append(result)
                 self._trim_history()
-                
+
                 return result
-                
+
             except Exception as e:
                 logger.error(f"Agent check failed: {e}")
                 return DiagnosticResult(
-                    check_type='agents',
-                    status='error',
+                    check_type="agents",
+                    status="error",
                     value=None,
-                    metadata={'error': str(e)}
+                    metadata={"error": str(e)},
                 )
-    
+
     class PerformanceMonitor(BaseMonitor):
         """Monitors system performance metrics."""
-        
+
         async def check(self) -> DiagnosticResult:
             try:
                 perf_info = await self.diagnostics._check_performance()
-                
-                response_time = perf_info['avg_response_time']
-                threshold = self.diagnostics.config.get(
-                    'max_response_time',
-                    1000
-                )
-                
-                status = 'healthy' if response_time < threshold else 'warning'
-                
+
+                response_time = perf_info["avg_response_time"]
+                threshold = self.diagnostics.config.get("max_response_time", 1000)
+
+                status = "healthy" if response_time < threshold else "warning"
+
                 result = DiagnosticResult(
-                    check_type='performance',
+                    check_type="performance",
                     status=status,
                     value=response_time,
                     threshold=threshold,
-                    metadata=perf_info
+                    metadata=perf_info,
                 )
-                
+
                 self.history.append(result)
                 self._trim_history()
-                
+
                 return result
-                
+
             except Exception as e:
                 logger.error(f"Performance check failed: {e}")
                 return DiagnosticResult(
-                    check_type='performance',
-                    status='error',
+                    check_type="performance",
+                    status="error",
                     value=None,
-                    metadata={'error': str(e)}
+                    metadata={"error": str(e)},
                 )
-    
+
     class ErrorMonitor(BaseMonitor):
         """Monitors system errors and exceptions."""
-        
+
         async def check(self) -> DiagnosticResult:
             try:
                 error_info = self.diagnostics._check_errors()
-                
-                error_rate = error_info['error_rate']
-                threshold = self.diagnostics.config.get('max_error_rate', 0.1)
-                
-                status = 'healthy' if error_rate < threshold else 'warning'
-                
+
+                error_rate = error_info["error_rate"]
+                threshold = self.diagnostics.config.get("max_error_rate", 0.1)
+
+                status = "healthy" if error_rate < threshold else "warning"
+
                 result = DiagnosticResult(
-                    check_type='errors',
+                    check_type="errors",
                     status=status,
                     value=error_rate,
                     threshold=threshold,
-                    metadata=error_info
+                    metadata=error_info,
                 )
-                
+
                 self.history.append(result)
                 self._trim_history()
-                
+
                 return result
-                
+
             except Exception as e:
                 logger.error(f"Error check failed: {e}")
                 return DiagnosticResult(
-                    check_type='errors',
-                    status='error',
+                    check_type="errors",
+                    status="error",
                     value=None,
-                    metadata={'error': str(e)}
+                    metadata={"error": str(e)},
                 )
-    
+
     async def _check_plugins(self) -> Dict[str, Any]:
         """Check plugin health status."""
         plugins = []
-        
+
         try:
             # Get plugin information from core system
             plugin_list = self.thread_manager.get_plugins()
-            
+
             for plugin in plugin_list:
                 try:
                     health = plugin.health_check()
-                    plugins.append({
-                        'name': plugin.name,
-                        'status': health['status'],
-                        'message': health.get('message', ''),
-                        'metrics': health.get('metrics', {})
-                    })
+                    plugins.append(
+                        {
+                            "name": plugin.name,
+                            "status": health["status"],
+                            "message": health.get("message", ""),
+                            "metrics": health.get("metrics", {}),
+                        }
+                    )
                 except Exception as e:
-                    plugins.append({
-                        'name': plugin.name,
-                        'status': 'error',
-                        'message': str(e),
-                        'metrics': {}
-                    })
-            
+                    plugins.append(
+                        {
+                            "name": plugin.name,
+                            "status": "error",
+                            "message": str(e),
+                            "metrics": {},
+                        }
+                    )
+
             return {
-                'plugins': plugins,
-                'total': len(plugins),
-                'healthy': len([p for p in plugins if p['status'] == 'healthy']),
-                'timestamp': datetime.utcnow().isoformat()
+                "plugins": plugins,
+                "total": len(plugins),
+                "healthy": len([p for p in plugins if p["status"] == "healthy"]),
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
         except Exception as e:
             logger.error(f"Plugin check failed: {e}")
             return {
-                'plugins': [],
-                'total': 0,
-                'healthy': 0,
-                'error': str(e),
-                'timestamp': datetime.utcnow().isoformat()
+                "plugins": [],
+                "total": 0,
+                "healthy": 0,
+                "error": str(e),
+                "timestamp": datetime.utcnow().isoformat(),
             }
-    
+
     async def _check_agents(self) -> Dict[str, Any]:
         """Check agent health status."""
         agents = []
-        
+
         try:
             # Get agent information from core system
             agent_list = self.thread_manager.get_agents()
-            
+
             for agent in agent_list:
                 try:
                     status = await agent.get_status()
-                    agents.append({
-                        'name': agent.name,
-                        'status': status['status'],
-                        'message': status.get('message', ''),
-                        'metrics': status.get('metrics', {})
-                    })
+                    agents.append(
+                        {
+                            "name": agent.name,
+                            "status": status["status"],
+                            "message": status.get("message", ""),
+                            "metrics": status.get("metrics", {}),
+                        }
+                    )
                 except Exception as e:
-                    agents.append({
-                        'name': agent.name,
-                        'status': 'error',
-                        'message': str(e),
-                        'metrics': {}
-                    })
-            
+                    agents.append(
+                        {
+                            "name": agent.name,
+                            "status": "error",
+                            "message": str(e),
+                            "metrics": {},
+                        }
+                    )
+
             return {
-                'agents': agents,
-                'total': len(agents),
-                'healthy': len([a for a in agents if a['status'] == 'healthy']),
-                'timestamp': datetime.utcnow().isoformat()
+                "agents": agents,
+                "total": len(agents),
+                "healthy": len([a for a in agents if a["status"] == "healthy"]),
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
         except Exception as e:
             logger.error(f"Agent check failed: {e}")
             return {
-                'agents': [],
-                'total': 0,
-                'healthy': 0,
-                'error': str(e),
-                'timestamp': datetime.utcnow().isoformat()
+                "agents": [],
+                "total": 0,
+                "healthy": 0,
+                "error": str(e),
+                "timestamp": datetime.utcnow().isoformat(),
             }
-    
+
     async def _check_performance(self) -> Dict[str, Any]:
         """Check system performance metrics."""
         try:
             # Get performance metrics from core system
             metrics = self.thread_manager.get_performance_metrics()
-            
+
             return {
-                'avg_response_time': metrics['response_time'],
-                'throughput': metrics['throughput'],
-                'cpu_usage': metrics['cpu_usage'],
-                'memory_usage': metrics['memory_usage'],
-                'timestamp': datetime.utcnow().isoformat()
+                "avg_response_time": metrics["response_time"],
+                "throughput": metrics["throughput"],
+                "cpu_usage": metrics["cpu_usage"],
+                "memory_usage": metrics["memory_usage"],
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
         except Exception as e:
             logger.error(f"Performance check failed: {e}")
-            return {
-                'error': str(e),
-                'timestamp': datetime.utcnow().isoformat()
-            }
-    
+            return {"error": str(e), "timestamp": datetime.utcnow().isoformat()}
+
     def _check_errors(self) -> Dict[str, Any]:
         """Check system error rates and patterns."""
         try:
             total_operations = sum(
-                1 for r in self.check_results
+                1
+                for r in self.check_results
                 if r.timestamp > datetime.utcnow() - timedelta(hours=1)
             )
-            
+
             error_count = sum(
-                1 for r in self.check_results
-                if r.status == 'error' and
-                r.timestamp > datetime.utcnow() - timedelta(hours=1)
+                1
+                for r in self.check_results
+                if r.status == "error"
+                and r.timestamp > datetime.utcnow() - timedelta(hours=1)
             )
-            
+
             error_rate = error_count / total_operations if total_operations else 0
-            
+
             return {
-                'error_rate': error_rate,
-                'error_count': error_count,
-                'total_operations': total_operations,
-                'timestamp': datetime.utcnow().isoformat()
+                "error_rate": error_rate,
+                "error_count": error_count,
+                "total_operations": total_operations,
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
         except Exception as e:
             logger.error(f"Error check failed: {e}")
-            return {
-                'error': str(e),
-                'timestamp': datetime.utcnow().isoformat()
-            }
-    
+            return {"error": str(e), "timestamp": datetime.utcnow().isoformat()}
+
     async def run_diagnostics(self) -> Dict[str, Any]:
         """Run all diagnostic checks."""
         try:
             results = {}
-            
+
             # Run all monitor checks
             for name, monitor in self.monitors.items():
                 try:
                     result = await monitor.check()
                     results[name] = result.to_dict()
                 except Exception as e:
                     logger.error(f"{name} check failed: {e}")
-                    results[name] = {
-                        'status': 'error',
-                        'error': str(e)
-                    }
-            
+                    results[name] = {"status": "error", "error": str(e)}
+
             # Store results
             self._store_results(results)
-            
+
             # Check for alerts
             await self._check_alerts(results)
-            
+
             return {
-                'status': 'success',
-                'timestamp': datetime.utcnow().isoformat(),
-                'results': results
+                "status": "success",
+                "timestamp": datetime.utcnow().isoformat(),
+                "results": results,
             }
-            
+
         except Exception as e:
             logger.error(f"Diagnostics failed: {e}")
             return {
-                'status': 'error',
-                'error': str(e),
-                'timestamp': datetime.utcnow().isoformat()
+                "status": "error",
+                "error": str(e),
+                "timestamp": datetime.utcnow().isoformat(),
             }
-    
+
     def _store_results(self, results: Dict[str, Any]) -> None:
         """Store diagnostic results."""
         try:
             # Store in memory
             for check_type, result in results.items():
                 if isinstance(result, dict):
                     self.check_results.append(
                         DiagnosticResult(
                             check_type=check_type,
-                            status=result['status'],
-                            value=result.get('value'),
-                            threshold=result.get('threshold'),
-                            metadata=result.get('metadata', {})
+                            status=result["status"],
+                            value=result.get("value"),
+                            threshold=result.get("threshold"),
+                            metadata=result.get("metadata", {}),
                         )
                     )
-            
+
             # Trim history
-            while len(self.check_results) > self.config['max_history']:
+            while len(self.check_results) > self.config["max_history"]:
                 self.check_results.pop(0)
-            
+
             # Store in codex
             self.codex.store_memory(
                 content={
-                    'type': 'diagnostic_results',
-                    'results': results,
-                    'timestamp': datetime.utcnow().isoformat()
+                    "type": "diagnostic_results",
+                    "results": results,
+                    "timestamp": datetime.utcnow().isoformat(),
                 },
-                source='system_diagnostics',
-                tags=['diagnostics', 'system_health'],
-                confidence=1.0
+                source="system_diagnostics",
+                tags=["diagnostics", "system_health"],
+                confidence=1.0,
             )
-            
+
         except Exception as e:
             logger.error(f"Failed to store results: {e}")
-    
+
     async def _check_alerts(self, results: Dict[str, Any]) -> None:
         """Check results for alert conditions."""
         try:
             alerts = []
-            
+
             for check_type, result in results.items():
                 if isinstance(result, dict):
-                    if result['status'] in ('warning', 'critical', 'error'):
-                        alerts.append({
-                            'type': check_type,
-                            'status': result['status'],
-                            'message': f"{check_type} check {result['status']}",
-                            'details': result
-                        })
-            
+                    if result["status"] in ("warning", "critical", "error"):
+                        alerts.append(
+                            {
+                                "type": check_type,
+                                "status": result["status"],
+                                "message": f"{check_type} check {result['status']}",
+                                "details": result,
+                            }
+                        )
+
             if alerts:
                 await self._send_alerts(alerts)
-                
+
         except Exception as e:
             logger.error(f"Alert check failed: {e}")
-    
+
     async def _send_alerts(self, alerts: List[Dict[str, Any]]) -> None:
         """Send alerts through configured channels."""
-        for channel in self.config['alert_channels']:
+        for channel in self.config["alert_channels"]:
             try:
-                if channel == 'internal':
+                if channel == "internal":
                     # Store in codex
                     self.codex.store_memory(
                         content={
-                            'type': 'system_alerts',
-                            'alerts': alerts,
-                            'timestamp': datetime.utcnow().isoformat()
+                            "type": "system_alerts",
+                            "alerts": alerts,
+                            "timestamp": datetime.utcnow().isoformat(),
                         },
-                        source='system_diagnostics',
-                        tags=['alerts', 'system_health'],
-                        confidence=1.0
+                        source="system_diagnostics",
+                        tags=["alerts", "system_health"],
+                        confidence=1.0,
                     )
-                
-                elif channel == 'log':
+
+                elif channel == "log":
                     for alert in alerts:
                         logger.warning(
                             f"System Alert: {alert['type']} - {alert['message']}"
                         )
-                
-                elif channel == 'metrics':
+
+                elif channel == "metrics":
                     # Update metrics
                     for alert in alerts:
-                        self.thread_manager.update_metrics({
-                            f"alert_{alert['type']}": 1,
-                            'alert_status': alert['status']
-                        })
-                
+                        self.thread_manager.update_metrics(
+                            {
+                                f"alert_{alert['type']}": 1,
+                                "alert_status": alert["status"],
+                            }
+                        )
+
             except Exception as e:
                 logger.error(f"Failed to send alert to {channel}: {e}")
-    
+
     async def _diagnostic_loop(self) -> None:
         """Main diagnostic loop."""
         while self.running:
             try:
                 # Run diagnostics
                 await self.run_diagnostics()
-                
+
                 # Update last check time
                 self.last_check = datetime.utcnow()
-                
+
                 # Wait for next interval
-                await asyncio.sleep(self.config['check_interval'])
-                
+                await asyncio.sleep(self.config["check_interval"])
+
             except Exception as e:
                 logger.error(f"Diagnostic loop error: {e}")
-                await self._handle_error('diagnostic_loop', e)
+                await self._handle_error("diagnostic_loop", e)
                 await asyncio.sleep(5)  # Error backoff
-    
-    async def _handle_error(
-        self,
-        component: str,
-        error: Exception
-    ) -> None:
+
+    async def _handle_error(self, component: str, error: Exception) -> None:
         """Handle component errors."""
         try:
             # Update error count
             self.error_count[component] = self.error_count.get(component, 0) + 1
-            
+
             # Check if recovery needed
             if (
-                self.error_count[component] >=
-                self.config['failure_handling']['max_retries']
+                self.error_count[component]
+                >= self.config["failure_handling"]["max_retries"]
             ):
                 if not self.recovery_in_progress:
                     await self._initiate_recovery(component)
-            
+
         except Exception as e:
             logger.error(f"Error handling failed: {e}")
-    
+
     async def _initiate_recovery(self, component: str) -> None:
         """Initiate component recovery."""
         try:
             self.recovery_in_progress = True
             logger.warning(f"Initiating recovery for {component}")
-            
+
             # Execute recovery actions
-            for action in self.config['failure_handling']['recovery_actions']:
+            for action in self.config["failure_handling"]["recovery_actions"]:
                 try:
-                    if action == 'restart_component':
+                    if action == "restart_component":
                         await self._restart_component(component)
-                    elif action == 'clear_cache':
+                    elif action == "clear_cache":
                         await self._clear_cache()
-                    elif action == 'reload_config':
+                    elif action == "reload_config":
                         await self._reload_config()
                 except Exception as e:
                     logger.error(f"Recovery action {action} failed: {e}")
-            
+
             # Reset error count
             self.error_count[component] = 0
-            
+
         except Exception as e:
             logger.error(f"Recovery failed: {e}")
         finally:
             self.recovery_in_progress = False
-    
+
     async def _restart_component(self, component: str) -> None:
         """Restart a system component."""
         try:
             logger.info(f"Restarting component: {component}")
-            
-            if component == 'diagnostic_loop':
+
+            if component == "diagnostic_loop":
                 self.running = False
                 if self.diagnostic_thread:
                     self.diagnostic_thread.join(timeout=5.0)
                 self.running = True
                 self._start_diagnostic_thread()
-            
+
             # Add other component restart logic as needed
-            
+
         except Exception as e:
             logger.error(f"Component restart failed: {e}")
-    
+
     async def _clear_cache(self) -> None:
         """Clear system caches."""
         try:
             logger.info("Clearing system caches")
-            
+
             # Clear diagnostic results
             self.check_results.clear()
-            
+
             # Clear monitor history
             for monitor in self.monitors.values():
                 monitor.history.clear()
-            
+
         except Exception as e:
             logger.error(f"Cache clear failed: {e}")
-    
+
     async def _reload_config(self) -> None:
         """Reload system configuration."""
         try:
             logger.info("Reloading configuration")
-            
+
             # Reload plugin configuration
             plugin_dir = Path(__file__).parent
-            with open(plugin_dir / 'plugin.json', 'r') as f:
-                self.config = json.load(f)['config']
-            
+            with open(plugin_dir / "plugin.json", "r") as f:
+                self.config = json.load(f)["config"]
+
             # Reinitialize monitors
             self.monitors = self._initialize_monitors()
-            
+
         except Exception as e:
             logger.error(f"Config reload failed: {e}")
-    
+
     def _start_diagnostic_thread(self) -> None:
         """Start the diagnostic thread."""
         self.diagnostic_thread = threading.Thread(
-            target=lambda: asyncio.run(self._diagnostic_loop()),
-            daemon=True
+            target=lambda: asyncio.run(self._diagnostic_loop()), daemon=True
         )
         self.diagnostic_thread.start()
 
+
 # Global diagnostics instance
 diagnostics: Optional[SystemDiagnostics] = None
 
+
 def init_plugin() -> bool:
     """Initialize the plugin."""
     try:
         # Load configuration
         plugin_dir = Path(__file__).parent
-        with open(plugin_dir / 'plugin.json', 'r') as f:
+        with open(plugin_dir / "plugin.json", "r") as f:
             config = json.load(f)
-        
+
         # Create and start diagnostics
         global diagnostics
-        diagnostics = SystemDiagnostics(config['config'])
+        diagnostics = SystemDiagnostics(config["config"])
         diagnostics.running = True
         diagnostics._start_diagnostic_thread()
-        
+
         return True
-        
+
     except Exception as e:
         logger.error(f"Plugin initialization failed: {e}")
         return False
 
+
 def cleanup() -> bool:
     """Clean up plugin resources."""
     try:
         if diagnostics:
             diagnostics.running = False
             if diagnostics.diagnostic_thread:
                 diagnostics.diagnostic_thread.join(timeout=5.0)
         return True
     except Exception as e:
         logger.error(f"Plugin cleanup failed: {e}")
         return False
 
+
 def get_metadata() -> Dict[str, Any]:
     """Return plugin metadata."""
     try:
         plugin_dir = Path(__file__).parent
-        with open(plugin_dir / 'plugin.json', 'r') as f:
+        with open(plugin_dir / "plugin.json", "r") as f:
             return json.load(f)
     except Exception as e:
         logger.error(f"Failed to load metadata: {e}")
         return {}
 
+
 def health_check() -> Dict[str, Any]:
     """Return plugin health status."""
     if not diagnostics:
-        return {
-            'status': 'error',
-            'message': 'Diagnostics not initialized'
-        }
-    
+        return {"status": "error", "message": "Diagnostics not initialized"}
+
     try:
         if not diagnostics.last_check:
-            return {
-                'status': 'warning',
-                'message': 'No diagnostics run yet'
-            }
-        
+            return {"status": "warning", "message": "No diagnostics run yet"}
+
         age = datetime.utcnow() - diagnostics.last_check
-        if age > timedelta(
-            seconds=diagnostics.config['check_interval'] * 2
-        ):
-            return {
-                'status': 'warning',
-                'message': f'Diagnostics delayed: {age}'
-            }
-        
+        if age > timedelta(seconds=diagnostics.config["check_interval"] * 2):
+            return {"status": "warning", "message": f"Diagnostics delayed: {age}"}
+
         return {
-            'status': 'healthy',
-            'message': 'System diagnostics running normally',
-            'metrics': {
-                'last_check': diagnostics.last_check.isoformat(),
-                'results_count': len(diagnostics.check_results),
-                'monitors': list(diagnostics.monitors.keys())
-            }
+            "status": "healthy",
+            "message": "System diagnostics running normally",
+            "metrics": {
+                "last_check": diagnostics.last_check.isoformat(),
+                "results_count": len(diagnostics.check_results),
+                "monitors": list(diagnostics.monitors.keys()),
+            },
         }
-        
+
     except Exception as e:
-        return {
-            'status': 'error',
-            'message': f'Health check failed: {e}'
-        }
+        return {"status": "error", "message": f"Health check failed: {e}"}
+
 
 # Example usage:
 if __name__ == "__main__":
     # Initialize plugin
     if init_plugin():
         print("Plugin initialized successfully")
-        
+
         # Wait for some diagnostics
         time.sleep(10)
-        
+
         # Check health
         health = health_check()
         print("\nHealth Status:")
         print(json.dumps(health, indent=2))
-        
+
         # Cleanup
         cleanup()
     else:
         print("Plugin initialization failed")
diff --git a/pyproject.toml b/pyproject.toml
index 2692ca627649715b0234711595234796d9ce33c9..890bd4d662e23678d138ee9e0b374a959b5f25ef 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,23 +1,27 @@
 
 
 
 [project]
-name = "guardian"
+name = "guardian_codex"
 version = "0.1.0"
 description = "PulseOS Guardian Backend"
 authors = [
     { name="Catalyst Design Labs", email="dev@catalystlabs.ai" }
 ]
 dependencies = [
     "fastapi",
     "httpx",
     "python-dotenv",
     "uvicorn",
-    "pytest",
-    "black",
-    "flake8"
 ]
 requires-python = ">=3.10"
 
+[project.optional-dependencies]
+dev = [
+    "black",
+    "flake8",
+    "pytest",
+]
+
 [tool.setuptools.packages.find]
 include = ["guardian", "guardian_codex"]
diff --git a/scripts/generate_docs.py b/scripts/generate_docs.py
index ac34aeac11c0644a3085bcef9a9ef971d594d6f3..1181b687a3978210cb22ed21c771adba64c27ef5 100644
--- a/scripts/generate_docs.py
+++ b/scripts/generate_docs.py
@@ -1,526 +1,499 @@
 #!/usr/bin/env python3
 """
 Documentation Generator
 ---------------------
 Generates comprehensive system documentation from codebase.
 """
 
 import ast
 import inspect
 import json
 import logging
 import os
 import re
 from datetime import datetime
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Set, Tuple
+from guardian.logging_config import configure_logging
 
 # Configure logging
-logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
-)
+configure_logging()
 logger = logging.getLogger(__name__)
 
+
 class DocGenerator:
     """Documentation generator for the system."""
-    
+
     def __init__(self):
         self.root_dir = Path(__file__).parent.parent
-        self.docs_dir = self.root_dir / 'docs'
-        self.output_dir = self.docs_dir / 'generated'
-        
+        self.docs_dir = self.root_dir / "docs"
+        self.output_dir = self.docs_dir / "generated"
+
         # Documentation sections
         self.sections = {
-            'overview': 'System Overview',
-            'architecture': 'System Architecture',
-            'components': 'Core Components',
-            'plugins': 'Plugin System',
-            'agents': 'Agent System',
-            'api': 'API Reference',
-            'deployment': 'Deployment Guide'
+            "overview": "System Overview",
+            "architecture": "System Architecture",
+            "components": "Core Components",
+            "plugins": "Plugin System",
+            "agents": "Agent System",
+            "api": "API Reference",
+            "deployment": "Deployment Guide",
         }
-    
+
     def generate_docs(self) -> None:
         """Generate all documentation."""
         try:
             logger.info("Generating system documentation...")
-            
+
             # Create output directory
             self.output_dir.mkdir(parents=True, exist_ok=True)
-            
+
             # Generate documentation sections
             self._generate_overview()
             self._generate_architecture()
             self._generate_components()
             self._generate_plugins()
             self._generate_agents()
             self._generate_api()
             self._generate_deployment()
-            
+
             # Generate index
             self._generate_index()
-            
+
             logger.info("Documentation generation complete")
-            
+
         except Exception as e:
             logger.error(f"Documentation generation failed: {e}")
             raise
-    
+
     def _generate_overview(self) -> None:
         """Generate system overview documentation."""
         content = [
             "# System Overview\n",
             "## Introduction\n",
             "Threadspace is a modular, extensible system designed for advanced "
             "thread management and plugin-based functionality.\n",
-            
             "## Key Features\n",
             "- Modular architecture with plugin support\n",
             "- Advanced thread management\n",
             "- Memory system with pattern recognition\n",
             "- Agent-based decision making\n",
             "- Comprehensive monitoring and diagnostics\n",
-            
             "## System Components\n",
             "1. GuardianOS - Core system management\n",
             "2. Thread Manager - Thread lifecycle and monitoring\n",
             "3. Plugin System - Extensible functionality\n",
             "4. Memory System - Data management and analysis\n",
             "5. Agent System - Autonomous operations\n",
-            
             "## Getting Started\n",
             "```bash\n",
             "# Install dependencies\n",
             "make install\n\n",
             "# Run system checks\n",
             "python scripts/system_check.py\n\n",
             "# Start the system\n",
             "python scripts/run_system.py\n",
-            "```\n"
+            "```\n",
         ]
-        
-        self._write_doc('overview', content)
-    
+
+        self._write_doc("overview", content)
+
     def _generate_architecture(self) -> None:
         """Generate architecture documentation."""
         content = [
             "# System Architecture\n",
-            
             "## High-Level Architecture\n",
             "```mermaid\n",
             "graph TB\n",
             "    Client[Client Applications] --> API[System API]\n",
             "    API --> Guardian[GuardianOS]\n",
             "    Guardian --> Components[Core Components]\n",
             "    Guardian --> Plugins[Plugin System]\n",
             "    Guardian --> Agents[Agent System]\n",
             "```\n",
-            
             "## Core Components\n",
             "### GuardianOS\n",
             "Central system orchestrator managing:\n",
             "- System initialization\n",
             "- Component lifecycle\n",
             "- Resource management\n",
             "- Error handling\n",
-            
             "### Thread Manager\n",
             "Handles:\n",
             "- Thread creation and lifecycle\n",
             "- Resource allocation\n",
             "- Performance monitoring\n",
             "- Thread synchronization\n",
-            
             "### Plugin System\n",
             "Provides:\n",
             "- Dynamic plugin loading\n",
             "- Plugin isolation\n",
             "- Resource management\n",
             "- Plugin communication\n",
-            
             "### Memory System\n",
             "Manages:\n",
             "- Data storage and retrieval\n",
             "- Pattern recognition\n",
             "- Memory optimization\n",
             "- Data analysis\n",
-            
             "## System Flow\n",
             "```mermaid\n",
             "sequenceDiagram\n",
             "    participant C as Client\n",
             "    participant G as GuardianOS\n",
             "    participant T as Thread Manager\n",
             "    participant P as Plugins\n",
             "    participant A as Agents\n",
             "    \n",
             "    C->>G: Request\n",
             "    G->>T: Allocate Resources\n",
             "    T->>P: Execute Plugins\n",
             "    P->>A: Process Data\n",
             "    A->>G: Return Results\n",
             "    G->>C: Response\n",
-            "```\n"
+            "```\n",
         ]
-        
-        self._write_doc('architecture', content)
-    
+
+        self._write_doc("architecture", content)
+
     def _generate_components(self) -> None:
         """Generate component documentation."""
         components = self._analyze_components()
-        
+
         content = [
             "# Core Components\n",
-            
             "## Component Overview\n",
-            "Detailed documentation of core system components.\n\n"
+            "Detailed documentation of core system components.\n\n",
         ]
-        
+
         for name, info in components.items():
-            content.extend([
-                f"## {name}\n",
-                f"{info['docstring']}\n\n",
-                "### Methods\n"
-            ])
-            
-            for method in info['methods']:
-                content.extend([
-                    f"#### `{method['name']}`\n",
-                    f"{method['docstring']}\n",
-                    "```python\n",
-                    f"{method['signature']}\n",
-                    "```\n\n"
-                ])
-        
-        self._write_doc('components', content)
-    
+            content.extend(
+                [f"## {name}\n", f"{info['docstring']}\n\n", "### Methods\n"]
+            )
+
+            for method in info["methods"]:
+                content.extend(
+                    [
+                        f"#### `{method['name']}`\n",
+                        f"{method['docstring']}\n",
+                        "```python\n",
+                        f"{method['signature']}\n",
+                        "```\n\n",
+                    ]
+                )
+
+        self._write_doc("components", content)
+
     def _generate_plugins(self) -> None:
         """Generate plugin documentation."""
         plugins = self._analyze_plugins()
-        
+
         content = [
             "# Plugin System\n",
-            
             "## Overview\n",
             "Documentation for the plugin system and available plugins.\n\n",
-            
             "## Plugin Architecture\n",
             "```mermaid\n",
             "graph TB\n",
             "    Loader[Plugin Loader] --> Registry[Plugin Registry]\n",
             "    Registry --> Plugins[Active Plugins]\n",
             "    Plugins --> Resources[System Resources]\n",
-            "```\n\n"
+            "```\n\n",
         ]
-        
+
         for name, info in plugins.items():
-            content.extend([
-                f"## {name}\n",
-                f"{info['description']}\n\n",
-                "### Configuration\n",
-                "```json\n",
-                f"{json.dumps(info['config'], indent=2)}\n",
-                "```\n\n",
-                "### Capabilities\n"
-            ])
-            
-            for capability in info['capabilities']:
+            content.extend(
+                [
+                    f"## {name}\n",
+                    f"{info['description']}\n\n",
+                    "### Configuration\n",
+                    "```json\n",
+                    f"{json.dumps(info['config'], indent=2)}\n",
+                    "```\n\n",
+                    "### Capabilities\n",
+                ]
+            )
+
+            for capability in info["capabilities"]:
                 content.append(f"- {capability}\n")
-            
+
             content.append("\n")
-        
-        self._write_doc('plugins', content)
-    
+
+        self._write_doc("plugins", content)
+
     def _generate_agents(self) -> None:
         """Generate agent documentation."""
         agents = self._analyze_agents()
-        
+
         content = [
             "# Agent System\n",
-            
             "## Overview\n",
             "Documentation for the autonomous agent system.\n\n",
-            
             "## Agent Architecture\n",
             "```mermaid\n",
             "graph TB\n",
             "    Vestige[Vestige Agent] --> Memory[Memory System]\n",
             "    Axis[Axis Agent] --> Decision[Decision Engine]\n",
             "    Echoform[Echoform Agent] --> State[State Manager]\n",
-            "```\n\n"
+            "```\n\n",
         ]
-        
+
         for name, info in agents.items():
-            content.extend([
-                f"## {name}\n",
-                f"{info['docstring']}\n\n",
-                "### Capabilities\n"
-            ])
-            
-            for capability in info['capabilities']:
+            content.extend(
+                [f"## {name}\n", f"{info['docstring']}\n\n", "### Capabilities\n"]
+            )
+
+            for capability in info["capabilities"]:
                 content.append(f"- {capability}\n")
-            
-            content.extend([
-                "\n### Methods\n"
-            ])
-            
-            for method in info['methods']:
-                content.extend([
-                    f"#### `{method['name']}`\n",
-                    f"{method['docstring']}\n",
-                    "```python\n",
-                    f"{method['signature']}\n",
-                    "```\n\n"
-                ])
-        
-        self._write_doc('agents', content)
-    
+
+            content.extend(["\n### Methods\n"])
+
+            for method in info["methods"]:
+                content.extend(
+                    [
+                        f"#### `{method['name']}`\n",
+                        f"{method['docstring']}\n",
+                        "```python\n",
+                        f"{method['signature']}\n",
+                        "```\n\n",
+                    ]
+                )
+
+        self._write_doc("agents", content)
+
     def _generate_api(self) -> None:
         """Generate API documentation."""
         content = [
             "# API Reference\n",
-            
             "## Overview\n",
             "Complete API reference for system interaction.\n\n",
-            
             "## Core API\n",
-            
             "### System Management\n",
             "```python\n",
             "# Initialize system\n",
             "system = SystemInitializer()\n",
             "await system.initialize()\n",
             "\n",
             "# Get system status\n",
             "status = await system.get_system_status()\n",
             "```\n",
-            
             "### Thread Management\n",
             "```python\n",
             "# Create thread\n",
             "thread_id = thread_manager.create_thread(\n",
             "    name='worker',\n",
             "    target=worker_function\n",
             ")\n",
             "\n",
             "# Monitor thread\n",
             "info = thread_manager.get_thread_info(thread_id)\n",
             "```\n",
-            
             "### Plugin Management\n",
             "```python\n",
             "# Load plugin\n",
             "plugin = plugin_loader.load_plugin('plugin_name')\n",
             "\n",
             "# Execute plugin\n",
             "result = await plugin.execute(data)\n",
             "```\n",
-            
             "### Memory Operations\n",
             "```python\n",
             "# Store memory\n",
             "memory_id = codex.store_memory(\n",
             "    content=data,\n",
             "    source='application',\n",
             "    tags=['important']\n",
             ")\n",
             "\n",
             "# Query memory\n",
             "result = codex.query_memory(memory_id)\n",
             "```\n",
-            
             "### Agent Interaction\n",
             "```python\n",
             "# Process with Vestige\n",
             "result = await vestige.process_memory(\n",
             "    memory_id,\n",
             "    context={}\n",
             ")\n",
             "\n",
             "# Make decision with Axis\n",
             "decision = await axis.make_decision(\n",
             "    decision_type='action',\n",
             "    context={},\n",
             "    options=[]\n",
             ")\n",
-            "```\n"
+            "```\n",
         ]
-        
-        self._write_doc('api', content)
-    
+
+        self._write_doc("api", content)
+
     def _generate_deployment(self) -> None:
         """Generate deployment documentation."""
         content = [
             "# Deployment Guide\n",
-            
             "## Requirements\n",
             "- Python 3.8 or higher\n",
             "- Required packages (see requirements.txt)\n",
             "- Sufficient system resources\n",
-            
             "## Installation\n",
             "```bash\n",
             "# Clone repository\n",
             "git clone https://github.com/threadspace/threadspace.git\n",
             "cd threadspace\n",
             "\n",
             "# Create virtual environment\n",
             "python -m venv venv\n",
             "source venv/bin/activate  # Linux/Mac\n",
             "# venv\\Scripts\\activate  # Windows\n",
             "\n",
             "# Install dependencies\n",
             "make install\n",
             "```\n",
-            
             "## Configuration\n",
             "1. Copy `.env.template` to `.env`\n",
             "2. Configure environment variables\n",
             "3. Adjust system settings in `config/`\n",
-            
             "## Running the System\n",
             "```bash\n",
             "# Run system checks\n",
             "python scripts/system_check.py\n",
             "\n",
             "# Start the system\n",
             "python scripts/run_system.py\n",
             "```\n",
-            
             "## Monitoring\n",
             "- Check system status: `http://localhost:8000/status`\n",
             "- View metrics: `http://localhost:9090`\n",
             "- Check logs: `tail -f logs/system.log`\n",
-            
             "## Troubleshooting\n",
             "1. Check system logs\n",
             "2. Run diagnostics plugin\n",
             "3. Check component status\n",
             "4. Verify configuration\n",
-            
             "## Security\n",
             "- Keep system updated\n",
             "- Monitor access logs\n",
             "- Regular security audits\n",
-            "- Follow security guidelines\n"
+            "- Follow security guidelines\n",
         ]
-        
-        self._write_doc('deployment', content)
-    
+
+        self._write_doc("deployment", content)
+
     def _generate_index(self) -> None:
         """Generate documentation index."""
         content = [
             "# System Documentation\n",
             f"Generated: {datetime.utcnow().isoformat()}\n\n",
-            "## Contents\n"
+            "## Contents\n",
         ]
-        
+
         for section, title in self.sections.items():
             content.append(f"- [{title}]({section}.md)\n")
-        
-        self._write_doc('index', content)
-    
+
+        self._write_doc("index", content)
+
     def _analyze_components(self) -> Dict[str, Any]:
         """Analyze core components."""
         components = {}
-        
+
         component_files = [
-            ('GuardianOS', 'guardian/system_init.py'),
-            ('ThreadManager', 'guardian/threads/thread_manager.py'),
-            ('PluginLoader', 'guardian/plugin_loader.py'),
-            ('CodexAwareness', 'guardian/codex_awareness.py'),
-            ('MetacognitionEngine', 'guardian/metacognition.py')
+            ("GuardianOS", "guardian/system_init.py"),
+            ("ThreadManager", "guardian/threads/thread_manager.py"),
+            ("PluginLoader", "guardian/plugin_loader.py"),
+            ("CodexAwareness", "guardian/codex_awareness.py"),
+            ("MetacognitionEngine", "guardian/metacognition.py"),
         ]
-        
+
         for name, path in component_files:
             file_path = self.root_dir / path
             if file_path.exists():
                 components[name] = self._analyze_python_file(file_path)
-        
+
         return components
-    
+
     def _analyze_plugins(self) -> Dict[str, Any]:
         """Analyze plugins."""
         plugins = {}
-        plugins_dir = self.root_dir / 'plugins'
-        
+        plugins_dir = self.root_dir / "plugins"
+
         if plugins_dir.exists():
             for plugin_dir in plugins_dir.iterdir():
-                if plugin_dir.is_dir() and not plugin_dir.name.startswith('__'):
-                    config_file = plugin_dir / 'plugin.json'
+                if plugin_dir.is_dir() and not plugin_dir.name.startswith("__"):
+                    config_file = plugin_dir / "plugin.json"
                     if config_file.exists():
-                        with open(config_file, 'r') as f:
+                        with open(config_file, "r") as f:
                             plugins[plugin_dir.name] = json.load(f)
-        
+
         return plugins
-    
+
     def _analyze_agents(self) -> Dict[str, Any]:
         """Analyze agents."""
         agents = {}
-        agents_dir = self.root_dir / 'guardian/agents'
-        
+        agents_dir = self.root_dir / "guardian/agents"
+
         if agents_dir.exists():
-            for agent_file in agents_dir.glob('*.py'):
-                if not agent_file.name.startswith('__'):
+            for agent_file in agents_dir.glob("*.py"):
+                if not agent_file.name.startswith("__"):
                     agents[agent_file.stem] = self._analyze_python_file(agent_file)
-        
+
         return agents
-    
+
     def _analyze_python_file(self, file_path: Path) -> Dict[str, Any]:
         """Analyze a Python source file."""
-        with open(file_path, 'r') as f:
+        with open(file_path, "r") as f:
             tree = ast.parse(f.read())
-        
+
         result = {
-            'docstring': ast.get_docstring(tree) or 'No description available.',
-            'methods': []
+            "docstring": ast.get_docstring(tree) or "No description available.",
+            "methods": [],
         }
-        
+
         for node in ast.walk(tree):
             if isinstance(node, ast.FunctionDef):
                 method = {
-                    'name': node.name,
-                    'docstring': ast.get_docstring(node) or 'No description available.',
-                    'signature': self._get_function_signature(node)
+                    "name": node.name,
+                    "docstring": ast.get_docstring(node) or "No description available.",
+                    "signature": self._get_function_signature(node),
                 }
-                result['methods'].append(method)
-        
+                result["methods"].append(method)
+
         return result
-    
+
     def _get_function_signature(self, node: ast.FunctionDef) -> str:
         """Get function signature as string."""
         args = []
-        
+
         # Add arguments
         for arg in node.args.args:
             args.append(arg.arg)
-        
+
         # Add *args if present
         if node.args.vararg:
             args.append(f"*{node.args.vararg.arg}")
-        
+
         # Add **kwargs if present
         if node.args.kwarg:
             args.append(f"**{node.args.kwarg.arg}")
-        
+
         return f"def {node.name}({', '.join(args)}):"
-    
+
     def _write_doc(self, name: str, content: List[str]) -> None:
         """Write documentation file."""
         output_file = self.output_dir / f"{name}.md"
-        with open(output_file, 'w') as f:
+        with open(output_file, "w") as f:
             f.writelines(content)
         logger.info(f"Generated {name} documentation")
 
+
 def main():
     """Generate system documentation."""
     try:
         generator = DocGenerator()
         generator.generate_docs()
     except Exception as e:
         logger.error(f"Documentation generation failed: {e}")
         raise
 
+
 if __name__ == "__main__":
     main()
diff --git a/scripts/run_system.py b/scripts/run_system.py
index 5bf1cbdc091526d4dff98c31b31a6d452dcbb27e..189ba4eb74ad6c1fbc801eac1b25b06dedb3724d 100644
--- a/scripts/run_system.py
+++ b/scripts/run_system.py
@@ -1,253 +1,250 @@
 #!/usr/bin/env python3
 """
 Threadspace System Runner
 -----------------------
 Initializes and runs the complete system with monitoring.
 """
 
 import argparse
 import asyncio
 import json
 import logging
 import signal
 import sys
 import time
 from datetime import datetime
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 from guardian.system_init import SystemInitializer
 from scripts.system_check import SystemCheck
+from guardian.logging_config import configure_logging
 
 # Configure logging
-logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
-)
+configure_logging()
 logger = logging.getLogger(__name__)
 
+
 class SystemRunner:
     """Manages system lifecycle and monitoring."""
-    
+
     def __init__(self, config_path: Optional[str] = None):
         self.config_path = config_path
         self.initializer = SystemInitializer()
         self.running = False
         self.start_time = None
         self.stats: Dict[str, Any] = {}
-    
+
     async def start(self) -> None:
         """Start the system."""
         try:
             logger.info("Starting Threadspace system...")
-            
+
             # Run system checks
             await self._run_checks()
-            
+
             # Initialize system
             await self._initialize_system()
-            
+
             # Start monitoring
             self.running = True
             self.start_time = datetime.utcnow()
             await self._monitor_system()
-            
+
         except Exception as e:
             logger.error(f"System start failed: {e}")
             raise
-    
+
     async def stop(self) -> None:
         """Stop the system."""
         try:
             logger.info("Stopping Threadspace system...")
             self.running = False
-            
+
             # Cleanup
             await self.initializer.cleanup()
-            
+
             # Print final stats
             self._print_final_stats()
-            
+
         except Exception as e:
             logger.error(f"System stop failed: {e}")
             raise
-    
+
     async def _run_checks(self) -> None:
         """Run system checks."""
         logger.info("Running system checks...")
-        
+
         checker = SystemCheck()
         results = checker.run_checks()
-        
-        if results['status'] == 'error':
+
+        if results["status"] == "error":
             raise RuntimeError("System checks failed")
-        elif results['status'] == 'warning':
+        elif results["status"] == "warning":
             logger.warning("System checks completed with warnings")
         else:
             logger.info("System checks passed")
-    
+
     async def _initialize_system(self) -> None:
         """Initialize system components."""
         logger.info("Initializing system components...")
-        
+
         # Load configuration
         if self.config_path:
             self.initializer.load_config(self.config_path)
-        
+
         # Initialize system
         success = await self.initializer.initialize()
         if not success:
             raise RuntimeError("System initialization failed")
-        
+
         logger.info("System initialized successfully")
-    
+
     async def _monitor_system(self) -> None:
         """Monitor system health and performance."""
         logger.info("Starting system monitoring...")
-        
+
         while self.running:
             try:
                 # Get system status
                 status = await self.initializer.get_system_status()
                 self._update_stats(status)
-                
+
                 # Print status
                 self._print_status()
-                
+
                 # Check for issues
-                if status['status'] != 'healthy':
+                if status["status"] != "healthy":
                     logger.warning(f"System status: {status['status']}")
-                    if status['status'] == 'error':
+                    if status["status"] == "error":
                         await self._handle_system_error(status)
-                
+
                 # Wait before next check
                 await asyncio.sleep(5)
-                
+
             except Exception as e:
                 logger.error(f"Monitoring error: {e}")
                 await asyncio.sleep(5)  # Error backoff
-    
+
     def _update_stats(self, status: Dict[str, Any]) -> None:
         """Update system statistics."""
         self.stats = {
-            'uptime': self._get_uptime(),
-            'status': status['status'],
-            'components': {
-                name: component['status']
-                for name, component in status.get('components', {}).items()
+            "uptime": self._get_uptime(),
+            "status": status["status"],
+            "components": {
+                name: component["status"]
+                for name, component in status.get("components", {}).items()
             },
-            'metrics': status.get('metrics', {}),
-            'memory_usage': status.get('memory_usage', {}),
-            'thread_count': status.get('thread_count', 0),
-            'plugin_count': status.get('plugin_count', 0),
-            'error_count': status.get('error_count', 0)
+            "metrics": status.get("metrics", {}),
+            "memory_usage": status.get("memory_usage", {}),
+            "thread_count": status.get("thread_count", 0),
+            "plugin_count": status.get("plugin_count", 0),
+            "error_count": status.get("error_count", 0),
         }
-    
+
     def _print_status(self) -> None:
         """Print current system status."""
         # Clear screen
         print("\033[2J\033[H")
-        
+
         print("=== Threadspace System Status ===")
         print(f"Uptime: {self.stats['uptime']}")
         print(f"Status: {self.stats['status']}")
-        
+
         print("\nComponents:")
-        for name, status in self.stats['components'].items():
+        for name, status in self.stats["components"].items():
             print(f"  {name}: {status}")
-        
+
         print("\nMetrics:")
-        for name, value in self.stats['metrics'].items():
+        for name, value in self.stats["metrics"].items():
             print(f"  {name}: {value}")
-        
+
         print("\nResources:")
         print(f"  Memory: {self.stats['memory_usage']}")
         print(f"  Threads: {self.stats['thread_count']}")
         print(f"  Plugins: {self.stats['plugin_count']}")
         print(f"  Errors: {self.stats['error_count']}")
-    
+
     def _print_final_stats(self) -> None:
         """Print final system statistics."""
         print("\n=== Final System Statistics ===")
         print(f"Total Uptime: {self._get_uptime()}")
         print(f"Final Status: {self.stats['status']}")
         print(f"Total Errors: {self.stats['error_count']}")
-        
-        if self.stats.get('metrics'):
+
+        if self.stats.get("metrics"):
             print("\nPerformance Metrics:")
-            for name, value in self.stats['metrics'].items():
+            for name, value in self.stats["metrics"].items():
                 print(f"  {name}: {value}")
-    
+
     def _get_uptime(self) -> str:
         """Get system uptime."""
         if not self.start_time:
             return "Not started"
-        
+
         delta = datetime.utcnow() - self.start_time
         hours = delta.seconds // 3600
         minutes = (delta.seconds % 3600) // 60
         seconds = delta.seconds % 60
-        
+
         return f"{delta.days}d {hours}h {minutes}m {seconds}s"
-    
+
     async def _handle_system_error(self, status: Dict[str, Any]) -> None:
         """Handle system error state."""
         logger.error(f"System error detected: {status.get('error', 'Unknown error')}")
-        
+
         # Get error details
         error_info = await self.initializer.get_error_info()
-        
+
         # Log error details
         logger.error("Error details:")
         for component, errors in error_info.items():
             for error in errors:
                 logger.error(f"  {component}: {error}")
-        
+
         # Check if recovery is possible
-        if status.get('recoverable'):
+        if status.get("recoverable"):
             logger.info("Attempting system recovery...")
             success = await self.initializer.attempt_recovery()
             if success:
                 logger.info("System recovery successful")
             else:
                 logger.error("System recovery failed")
         else:
             logger.error("System in unrecoverable state")
             await self.stop()
 
+
 async def main():
     """Run the system."""
     parser = argparse.ArgumentParser(description="Threadspace System Runner")
-    parser.add_argument(
-        "--config",
-        help="Path to configuration file",
-        default=None
-    )
+    parser.add_argument("--config", help="Path to configuration file", default=None)
     args = parser.parse_args()
-    
+
     runner = SystemRunner(args.config)
-    
+
     # Handle shutdown signals
     def signal_handler(sig, frame):
         logger.info("Shutdown signal received")
         asyncio.create_task(runner.stop())
-    
+
     signal.signal(signal.SIGINT, signal_handler)
     signal.signal(signal.SIGTERM, signal_handler)
-    
+
     try:
         await runner.start()
-        
+
         # Keep running until stopped
         while runner.running:
             await asyncio.sleep(1)
-            
+
     except Exception as e:
         logger.error(f"System error: {e}")
         await runner.stop()
         sys.exit(1)
-    
+
     sys.exit(0)
 
+
 if __name__ == "__main__":
     asyncio.run(main())
diff --git a/scripts/system_check.py b/scripts/system_check.py
index de46b57e73ae9d260d928aa2d7a4a9b73700cf05..ea91b47db4dbada7efcf5c329f05fc35d3e1ef78 100644
--- a/scripts/system_check.py
+++ b/scripts/system_check.py
@@ -1,356 +1,346 @@
 """
 System Diagnostic Checklist
 -------------------------
 Verifies system configuration and readiness for operation.
 """
 
 import json
 import logging
 import os
 import sys
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Tuple
+from guardian.logging_config import configure_logging
 
 # Configure logging
-logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
-)
+configure_logging()
 logger = logging.getLogger(__name__)
 
+
 class SystemCheck:
     """System configuration and readiness verification."""
-    
+
     def __init__(self):
         self.root_dir = Path(__file__).parent.parent
         self.results: Dict[str, Any] = {
-            'status': 'pending',
-            'checks': {},
-            'errors': [],
-            'warnings': []
+            "status": "pending",
+            "checks": {},
+            "errors": [],
+            "warnings": [],
         }
-    
+
     def run_checks(self) -> Dict[str, Any]:
         """Run all system checks."""
         try:
             logger.info("Starting system checks...")
-            
+
             # Core files check
             self._check_core_files()
-            
+
             # Configuration check
             self._check_configuration()
-            
+
             # Plugin check
             self._check_plugins()
-            
+
             # Documentation check
             self._check_documentation()
-            
+
             # Development setup check
             self._check_development_setup()
-            
+
             # Test suite check
             self._check_test_suite()
-            
+
             # Set final status
             self._set_final_status()
-            
+
             return self.results
-            
+
         except Exception as e:
             logger.error(f"System check failed: {e}")
-            self.results['status'] = 'error'
-            self.results['errors'].append(str(e))
+            self.results["status"] = "error"
+            self.results["errors"].append(str(e))
             return self.results
-    
+
     def _check_core_files(self) -> None:
         """Check core system files."""
         logger.info("Checking core files...")
-        
+
         core_files = [
-            'guardian/system_init.py',
-            'guardian/codex_awareness.py',
-            'guardian/metacognition.py',
-            'guardian/plugin_loader.py',
-            'guardian/threads/thread_manager.py',
-            'guardian/agents/vestige.py',
-            'guardian/agents/axis.py',
-            'guardian/agents/echoform.py'
+            "guardian/system_init.py",
+            "guardian/codex_awareness.py",
+            "guardian/metacognition.py",
+            "guardian/plugin_loader.py",
+            "guardian/threads/thread_manager.py",
+            "guardian/agents/vestige.py",
+            "guardian/agents/axis.py",
+            "guardian/agents/echoform.py",
         ]
-        
+
         missing_files = []
         for file in core_files:
             if not (self.root_dir / file).exists():
                 missing_files.append(file)
-        
-        self.results['checks']['core_files'] = {
-            'status': 'error' if missing_files else 'success',
-            'missing_files': missing_files
+
+        self.results["checks"]["core_files"] = {
+            "status": "error" if missing_files else "success",
+            "missing_files": missing_files,
         }
-        
+
         if missing_files:
-            self.results['errors'].append(
+            self.results["errors"].append(
                 f"Missing core files: {', '.join(missing_files)}"
             )
-    
+
     def _check_configuration(self) -> None:
         """Check system configuration."""
         logger.info("Checking configuration...")
-        
+
         config_files = [
-            '.env.template',
-            'guardian/config/system_config.py',
-            'setup.py',
-            'requirements.txt'
+            ".env.template",
+            "guardian/config/system_config.py",
+            "setup.py",
+            "requirements.txt",
         ]
-        
+
         missing_configs = []
         for file in config_files:
             if not (self.root_dir / file).exists():
                 missing_configs.append(file)
-        
+
         # Check .env.template content
         env_issues = []
-        env_path = self.root_dir / '.env.template'
+        env_path = self.root_dir / ".env.template"
         if env_path.exists():
             required_vars = [
-                'THREADSPACE_ENV',
-                'LOG_LEVEL',
-                'SYSTEM_NAME',
-                'PLUGIN_DIR'
+                "THREADSPACE_ENV",
+                "LOG_LEVEL",
+                "SYSTEM_NAME",
+                "PLUGIN_DIR",
             ]
-            
-            with open(env_path, 'r') as f:
+
+            with open(env_path, "r") as f:
                 content = f.read()
                 for var in required_vars:
                     if var not in content:
                         env_issues.append(f"Missing {var}")
-        
-        self.results['checks']['configuration'] = {
-            'status': 'error' if missing_configs or env_issues else 'success',
-            'missing_configs': missing_configs,
-            'env_issues': env_issues
+
+        self.results["checks"]["configuration"] = {
+            "status": "error" if missing_configs or env_issues else "success",
+            "missing_configs": missing_configs,
+            "env_issues": env_issues,
         }
-        
+
         if missing_configs:
-            self.results['errors'].append(
+            self.results["errors"].append(
                 f"Missing configuration files: {', '.join(missing_configs)}"
             )
         if env_issues:
-            self.results['warnings'].extend(env_issues)
-    
+            self.results["warnings"].extend(env_issues)
+
     def _check_plugins(self) -> None:
         """Check plugin system."""
         logger.info("Checking plugins...")
-        
-        plugins_dir = self.root_dir / 'plugins'
+
+        plugins_dir = self.root_dir / "plugins"
         if not plugins_dir.exists():
-            self.results['errors'].append("Plugins directory not found")
-            self.results['checks']['plugins'] = {'status': 'error'}
+            self.results["errors"].append("Plugins directory not found")
+            self.results["checks"]["plugins"] = {"status": "error"}
             return
-        
+
         plugin_issues = []
         for plugin_dir in plugins_dir.iterdir():
-            if plugin_dir.is_dir() and not plugin_dir.name.startswith('__'):
+            if plugin_dir.is_dir() and not plugin_dir.name.startswith("__"):
                 # Check plugin structure
-                required_files = [
-                    'plugin.json',
-                    'main.py'
-                ]
-                
+                required_files = ["plugin.json", "main.py"]
+
                 for file in required_files:
                     if not (plugin_dir / file).exists():
-                        plugin_issues.append(
-                            f"Missing {file} in {plugin_dir.name}"
-                        )
-                
+                        plugin_issues.append(f"Missing {file} in {plugin_dir.name}")
+
                 # Check plugin.json content
                 try:
-                    with open(plugin_dir / 'plugin.json', 'r') as f:
+                    with open(plugin_dir / "plugin.json", "r") as f:
                         config = json.load(f)
                         required_fields = [
-                            'name',
-                            'version',
-                            'description',
-                            'capabilities',
-                            'config'
+                            "name",
+                            "version",
+                            "description",
+                            "capabilities",
+                            "config",
                         ]
                         for field in required_fields:
                             if field not in config:
                                 plugin_issues.append(
                                     f"Missing {field} in {plugin_dir.name}/plugin.json"
                                 )
                 except Exception as e:
                     plugin_issues.append(
                         f"Invalid plugin.json in {plugin_dir.name}: {e}"
                     )
-        
-        self.results['checks']['plugins'] = {
-            'status': 'error' if plugin_issues else 'success',
-            'issues': plugin_issues
+
+        self.results["checks"]["plugins"] = {
+            "status": "error" if plugin_issues else "success",
+            "issues": plugin_issues,
         }
-        
+
         if plugin_issues:
-            self.results['warnings'].extend(plugin_issues)
-    
+            self.results["warnings"].extend(plugin_issues)
+
     def _check_documentation(self) -> None:
         """Check documentation files."""
         logger.info("Checking documentation...")
-        
+
         doc_files = [
-            'README.md',
-            'CONTRIBUTING.md',
-            'CODE_OF_CONDUCT.md',
-            'CHANGELOG.md',
-            'LICENSE',
-            'docs/plugin_development.md',
-            'docs/system_architecture.md'
+            "README.md",
+            "CONTRIBUTING.md",
+            "CODE_OF_CONDUCT.md",
+            "CHANGELOG.md",
+            "LICENSE",
+            "docs/plugin_development.md",
+            "docs/system_architecture.md",
         ]
-        
+
         missing_docs = []
         for file in doc_files:
             if not (self.root_dir / file).exists():
                 missing_docs.append(file)
-        
-        self.results['checks']['documentation'] = {
-            'status': 'error' if missing_docs else 'success',
-            'missing_docs': missing_docs
+
+        self.results["checks"]["documentation"] = {
+            "status": "error" if missing_docs else "success",
+            "missing_docs": missing_docs,
         }
-        
+
         if missing_docs:
-            self.results['warnings'].append(
+            self.results["warnings"].append(
                 f"Missing documentation files: {', '.join(missing_docs)}"
             )
-    
+
     def _check_development_setup(self) -> None:
         """Check development setup."""
         logger.info("Checking development setup...")
-        
+
         dev_files = [
-            '.pre-commit-config.yaml',
-            'Makefile',
-            '.github/ISSUE_TEMPLATE/bug_report.md',
-            '.github/ISSUE_TEMPLATE/feature_request.md',
-            '.github/pull_request_template.md'
+            ".pre-commit-config.yaml",
+            "Makefile",
+            ".github/ISSUE_TEMPLATE/bug_report.md",
+            ".github/ISSUE_TEMPLATE/feature_request.md",
+            ".github/pull_request_template.md",
         ]
-        
+
         missing_files = []
         for file in dev_files:
             if not (self.root_dir / file).exists():
                 missing_files.append(file)
-        
+
         # Check Makefile targets
         makefile_issues = []
-        makefile_path = self.root_dir / 'Makefile'
+        makefile_path = self.root_dir / "Makefile"
         if makefile_path.exists():
-            required_targets = [
-                'install',
-                'test',
-                'lint',
-                'format',
-                'clean'
-            ]
-            
-            with open(makefile_path, 'r') as f:
+            required_targets = ["install", "test", "lint", "format", "clean"]
+
+            with open(makefile_path, "r") as f:
                 content = f.read()
                 for target in required_targets:
                     if f"{target}:" not in content:
                         makefile_issues.append(f"Missing target: {target}")
-        
-        self.results['checks']['development'] = {
-            'status': 'error' if missing_files or makefile_issues else 'success',
-            'missing_files': missing_files,
-            'makefile_issues': makefile_issues
+
+        self.results["checks"]["development"] = {
+            "status": "error" if missing_files or makefile_issues else "success",
+            "missing_files": missing_files,
+            "makefile_issues": makefile_issues,
         }
-        
+
         if missing_files:
-            self.results['warnings'].append(
+            self.results["warnings"].append(
                 f"Missing development files: {', '.join(missing_files)}"
             )
         if makefile_issues:
-            self.results['warnings'].extend(makefile_issues)
-    
+            self.results["warnings"].extend(makefile_issues)
+
     def _check_test_suite(self) -> None:
         """Check test suite."""
         logger.info("Checking test suite...")
-        
+
         test_files = [
-            'tests/test_system_integration.py',
-            'tests/test_agents_and_plugins.py',
-            'tests/run_tests.py'
+            "tests/test_system_integration.py",
+            "tests/test_agents_and_plugins.py",
+            "tests/run_tests.py",
         ]
-        
+
         missing_tests = []
         for file in test_files:
             if not (self.root_dir / file).exists():
                 missing_tests.append(file)
-        
+
         # Check plugin tests
-        plugins_dir = self.root_dir / 'plugins'
+        plugins_dir = self.root_dir / "plugins"
         if plugins_dir.exists():
             for plugin_dir in plugins_dir.iterdir():
-                if plugin_dir.is_dir() and not plugin_dir.name.startswith('__'):
-                    test_dir = plugin_dir / 'tests'
+                if plugin_dir.is_dir() and not plugin_dir.name.startswith("__"):
+                    test_dir = plugin_dir / "tests"
                     if not test_dir.exists() or not any(test_dir.iterdir()):
                         missing_tests.append(
                             f"Missing tests for plugin: {plugin_dir.name}"
                         )
-        
-        self.results['checks']['tests'] = {
-            'status': 'error' if missing_tests else 'success',
-            'missing_tests': missing_tests
+
+        self.results["checks"]["tests"] = {
+            "status": "error" if missing_tests else "success",
+            "missing_tests": missing_tests,
         }
-        
+
         if missing_tests:
-            self.results['warnings'].append(
+            self.results["warnings"].append(
                 f"Missing test files: {', '.join(missing_tests)}"
             )
-    
+
     def _set_final_status(self) -> None:
         """Set final system status."""
-        if self.results['errors']:
-            self.results['status'] = 'error'
-        elif self.results['warnings']:
-            self.results['status'] = 'warning'
+        if self.results["errors"]:
+            self.results["status"] = "error"
+        elif self.results["warnings"]:
+            self.results["status"] = "warning"
         else:
-            self.results['status'] = 'success'
-    
+            self.results["status"] = "success"
+
     def print_results(self) -> None:
         """Print check results."""
         print("\n=== System Check Results ===")
         print(f"Status: {self.results['status'].upper()}")
-        
+
         print("\nChecks:")
-        for check, result in self.results['checks'].items():
+        for check, result in self.results["checks"].items():
             print(f"\n{check}:")
             print(f"  Status: {result['status']}")
             for key, value in result.items():
-                if key != 'status' and value:
+                if key != "status" and value:
                     print(f"  {key}: {value}")
-        
-        if self.results['errors']:
+
+        if self.results["errors"]:
             print("\nErrors:")
-            for error in self.results['errors']:
+            for error in self.results["errors"]:
                 print(f"  - {error}")
-        
-        if self.results['warnings']:
+
+        if self.results["warnings"]:
             print("\nWarnings:")
-            for warning in self.results['warnings']:
+            for warning in self.results["warnings"]:
                 print(f"  - {warning}")
 
+
 def main():
     """Run system checks."""
     checker = SystemCheck()
     results = checker.run_checks()
     checker.print_results()
-    
+
     # Exit with appropriate status code
-    if results['status'] == 'error':
+    if results["status"] == "error":
         sys.exit(1)
-    elif results['status'] == 'warning':
+    elif results["status"] == "warning":
         sys.exit(2)
     sys.exit(0)
 
+
 if __name__ == "__main__":
     main()
diff --git a/scripts/test_full_system.py b/scripts/test_full_system.py
index e63426ad316d842859f1ab496074db46e237cf04..2de508b6002f9133b3f3632c3ba2c6f367ac3b31 100644
--- a/scripts/test_full_system.py
+++ b/scripts/test_full_system.py
@@ -1,1044 +1,1064 @@
 #!/usr/bin/env python3
 """
 Full System Test Suite
 --------------------
 Comprehensive testing of all system components and integrations.
 """
 
 import asyncio
 import functools
 import json
 import logging
 import sys
 import threading
 import time
 from datetime import datetime
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Tuple
 
+
 def timeout(seconds: int) -> Callable:
     """Decorator to add timeout to test methods."""
+
     def decorator(func: Callable) -> Callable:
         @functools.wraps(func)
         async def wrapper(*args, **kwargs):
             try:
                 return await asyncio.wait_for(func(*args, **kwargs), timeout=seconds)
             except asyncio.TimeoutError:
                 logger.error(f"Test {func.__name__} timed out after {seconds} seconds")
                 return False
+
         return wrapper
+
     return decorator
 
+
 from guardian.codex_awareness import CodexAwareness, MemoryArtifact
 from guardian.metacognition import MetacognitionEngine
 from guardian.plugin_loader import PluginLoader
 from guardian.system_init import SystemInitializer
 from guardian.threads.thread_manager import ThreadManager
 from .system_check import SystemCheck
+from guardian.logging_config import configure_logging
 
 # Configure logging
-logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
-)
+configure_logging()
 logger = logging.getLogger(__name__)
 
+
 class SystemTestSuite:
     """Comprehensive system test suite."""
-    
+
     # Default timeout for tests in seconds
     TEST_TIMEOUT = 10
-    
+
     def __init__(self):
         self.results: Dict[str, Any] = {
-            'start_time': datetime.utcnow().isoformat(),
-            'end_time': None,
-            'duration': None,
-            'total_tests': 0,
-            'passed_tests': 0,
-            'failed_tests': 0,
-            'test_results': {}
+            "start_time": datetime.utcnow().isoformat(),
+            "end_time": None,
+            "duration": None,
+            "total_tests": 0,
+            "passed_tests": 0,
+            "failed_tests": 0,
+            "test_results": {},
         }
-        
+
         # Initialize system
         self.initializer = SystemInitializer()
         self._system = None  # Will be set after initialization
-    
+
     async def run_tests(self) -> Dict[str, Any]:
         """Run all system tests."""
         try:
             logger.info("Starting full system test suite...")
-            
+
             # System checks
             await self._run_test(
-                'system_checks',
+                "system_checks",
                 self._test_system_checks,
-                "System configuration and setup verification"
+                "System configuration and setup verification",
             )
-            
+
             # Initialization
             await self._run_test(
-                'system_init',
+                "system_init",
                 self._test_system_init,
-                "System initialization and boot sequence"
+                "System initialization and boot sequence",
             )
-            
+
             # Core components
             await self._run_test(
-                'thread_management',
+                "thread_management",
                 self._test_thread_management,
-                "Thread management and lifecycle"
+                "Thread management and lifecycle",
             )
-            
+
             await self._run_test(
-                'memory_system',
-                self._test_memory_system,
-                "Memory system operations"
+                "memory_system", self._test_memory_system, "Memory system operations"
             )
-            
+
             await self._run_test(
-                'plugin_system',
-                self._test_plugin_system,
-                "Plugin system functionality"
+                "plugin_system", self._test_plugin_system, "Plugin system functionality"
             )
-            
+
             # Agent tests
             await self._run_test(
-                'vestige_agent',
-                self._test_vestige_agent,
-                "Vestige agent operations"
+                "vestige_agent", self._test_vestige_agent, "Vestige agent operations"
             )
-            
+
             await self._run_test(
-                'axis_agent',
-                self._test_axis_agent,
-                "Axis agent operations"
+                "axis_agent", self._test_axis_agent, "Axis agent operations"
             )
-            
+
             await self._run_test(
-                'echoform_agent',
-                self._test_echoform_agent,
-                "Echoform agent operations"
+                "echoform_agent", self._test_echoform_agent, "Echoform agent operations"
             )
-            
+
             # Integration tests
             await self._run_test(
-                'plugin_integration',
+                "plugin_integration",
                 self._test_plugin_integration,
-                "Plugin integration and interaction"
+                "Plugin integration and interaction",
             )
-            
+
             await self._run_test(
-                'agent_integration',
+                "agent_integration",
                 self._test_agent_integration,
-                "Agent interaction and coordination"
+                "Agent interaction and coordination",
             )
-            
+
             # Error handling
             await self._run_test(
-                'error_handling',
+                "error_handling",
                 self._test_error_handling,
-                "System error handling and recovery"
+                "System error handling and recovery",
             )
-            
+
             # Performance
             await self._run_test(
-                'performance',
+                "performance",
                 self._test_performance,
-                "System performance and resource usage"
+                "System performance and resource usage",
             )
-            
+
             # Cleanup
             await self._run_test(
-                'system_cleanup',
+                "system_cleanup",
                 self._test_system_cleanup,
-                "System shutdown and cleanup"
+                "System shutdown and cleanup",
             )
-            
+
             # Finalize results
             self._finalize_results()
-            
+
             return self.results
-            
+
         except Exception as e:
             logger.error(f"Test suite failed: {e}")
-            self.results['status'] = 'error'
+            self.results["status"] = "error"
             return self.results
-    
-    async def _run_test(
-        self,
-        name: str,
-        test_func: Any,
-        description: str
-    ) -> None:
+
+    async def _run_test(self, name: str, test_func: Any, description: str) -> None:
         """Run a specific test."""
         logger.info(f"\nRunning test: {name}")
         logger.info(f"Description: {description}")
-        
+
         start_time = time.time()
-        self.results['total_tests'] += 1
-        
+        self.results["total_tests"] += 1
+
         try:
             result = await test_func()
             duration = time.time() - start_time
-            
-            self.results['test_results'][name] = {
-                'description': description,
-                'status': 'passed' if result else 'failed',
-                'duration': duration,
-                'timestamp': datetime.utcnow().isoformat()
+
+            self.results["test_results"][name] = {
+                "description": description,
+                "status": "passed" if result else "failed",
+                "duration": duration,
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
             if result:
-                self.results['passed_tests'] += 1
+                self.results["passed_tests"] += 1
                 logger.info(f"Test {name}: PASSED ({duration:.2f}s)")
             else:
-                self.results['failed_tests'] += 1
+                self.results["failed_tests"] += 1
                 logger.error(f"Test {name}: FAILED ({duration:.2f}s)")
-            
+
         except Exception as e:
             duration = time.time() - start_time
-            self.results['failed_tests'] += 1
-            self.results['test_results'][name] = {
-                'description': description,
-                'status': 'error',
-                'error': str(e),
-                'duration': duration,
-                'timestamp': datetime.utcnow().isoformat()
+            self.results["failed_tests"] += 1
+            self.results["test_results"][name] = {
+                "description": description,
+                "status": "error",
+                "error": str(e),
+                "duration": duration,
+                "timestamp": datetime.utcnow().isoformat(),
             }
             logger.error(f"Test {name}: ERROR - {e} ({duration:.2f}s)")
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_system_checks(self) -> bool:
         """Test system configuration and setup."""
         try:
             checker = SystemCheck()
             results = checker.run_checks()
-            return results['status'] != 'error'
+            return results["status"] != "error"
         except Exception as e:
             logger.error(f"System checks failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_system_init(self) -> bool:
         """Test system initialization."""
         try:
             success = await self.initializer.initialize()
             if not success:
                 return False
-            
+
             # Store reference to initialized system
             self._system = self.initializer._system
-            
+
             # Verify components
             status = await self.initializer.get_system_status()
-            return status['status'] == 'healthy'
-            
+            return status["status"] == "healthy"
+
         except Exception as e:
             logger.error(f"Initialization failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_thread_management(self) -> bool:
         """Test thread management."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Create and start test thread
             thread = threading.Thread(
-                target=lambda: time.sleep(0.1),
-                name="test_thread",
-                daemon=True
+                target=lambda: time.sleep(0.1), name="test_thread", daemon=True
             )
-            
-            self._system.thread_manager.register_thread(
-                "test_thread",
-                thread,
-                "worker"
-            )
-            
+
+            self._system.thread_manager.register_thread("test_thread", thread, "worker")
+
             self._system.thread_manager.start_thread("test_thread")
-            
+
             # Verify thread status
             info = self._system.thread_manager.get_thread_info()
-            if not info['active_count'] > 0:
+            if not info["active_count"] > 0:
                 logger.error("Thread not active after starting")
                 return False
-            
+
             # Wait for thread completion
-            success = self._system.thread_manager.join_thread("test_thread", timeout=2.0)
+            success = self._system.thread_manager.join_thread(
+                "test_thread", timeout=2.0
+            )
             if not success:
                 logger.error("Failed to join thread")
                 return False
-                
+
             return True
-            
+
         except Exception as e:
             logger.error(f"Thread management failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_memory_system(self) -> bool:
         """Test memory system operations."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Initialize memory path
-            memory_path = Path(__file__).parent.parent / 'guardian' / 'memory'
+            memory_path = Path(__file__).parent.parent / "guardian" / "memory"
             memory_path.mkdir(exist_ok=True)
-            
+
             # Store test memory
             test_content = {
-                'type': 'test_memory',
-                'data': 'test_data',
-                'timestamp': datetime.utcnow().isoformat()
+                "type": "test_memory",
+                "data": "test_data",
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
             # Store first memory
             artifact_id_1 = self._system.codex_awareness.store_memory(
                 content=test_content,
-                source='test',
-                tags=['test', 'memory_test'],
-                confidence=1.0
+                source="test",
+                tags=["test", "memory_test"],
+                confidence=1.0,
             )
-            
+
             # Store second related memory
             related_content = {
-                'type': 'related_memory',
-                'data': 'related_data',
-                'timestamp': datetime.utcnow().isoformat()
+                "type": "related_memory",
+                "data": "related_data",
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
             artifact_id_2 = self._system.codex_awareness.store_memory(
                 content=related_content,
-                source='test',
-                tags=['test', 'memory_test', 'related'],
+                source="test",
+                tags=["test", "memory_test", "related"],
                 confidence=0.9,
-                related_artifacts=[artifact_id_1]
+                related_artifacts=[artifact_id_1],
             )
-            
+
             # Query for the first memory by content
             results = self._system.codex_awareness.query_memory(
-                query='test_memory',
-                tags=['test'],
-                limit=1
+                query="test_memory", tags=["test"], limit=1
             )
-            
+
             if not results:
                 logger.error("Failed to retrieve stored memory")
                 return False
-            
+
             memory = results[0]
-            
+
             # Compare essential content fields
             stored_content = memory.content
-            if stored_content.get('type') != test_content['type'] or \
-               stored_content.get('data') != test_content['data']:
+            if (
+                stored_content.get("type") != test_content["type"]
+                or stored_content.get("data") != test_content["data"]
+            ):
                 logger.error("Retrieved memory content does not match stored content")
                 logger.error(f"Expected: {test_content}")
                 logger.error(f"Got: {stored_content}")
                 return False
-            
+
             # Test memory querying by tag
             tag_results = self._system.codex_awareness.query_memory(
-                query="",
-                tags=['memory_test', 'related'],
-                limit=1
+                query="", tags=["memory_test", "related"], limit=1
             )
-            
+
             if not tag_results:
                 logger.error("Failed to retrieve memory by tag")
                 return False
-                
+
             # Compare IDs if available, but don't fail if they don't match
-            if hasattr(tag_results[0], 'id') and tag_results[0].id != artifact_id_2:
-                logger.warning(f"Retrieved memory ID {tag_results[0].id} does not match expected {artifact_id_2}")
-            
+            if hasattr(tag_results[0], "id") and tag_results[0].id != artifact_id_2:
+                logger.warning(
+                    f"Retrieved memory ID {tag_results[0].id} does not match expected {artifact_id_2}"
+                )
+
             # Store multiple related memories to increase chance of detection
             for i in range(3):
                 related_content = {
-                    'type': 'related_memory',
-                    'data': f'test_data_{i}',
-                    'timestamp': datetime.utcnow().isoformat()
+                    "type": "related_memory",
+                    "data": f"test_data_{i}",
+                    "timestamp": datetime.utcnow().isoformat(),
                 }
-                
+
                 self._system.codex_awareness.store_memory(
                     content=related_content,
-                    source='test',
-                    tags=['test', 'memory_test', 'related'],
+                    source="test",
+                    tags=["test", "memory_test", "related"],
                     confidence=0.9,
-                    related_artifacts=[artifact_id_1]
+                    related_artifacts=[artifact_id_1],
                 )
-            
+
             # Test related memories with retries
             max_retries = 3
             success = False
             for attempt in range(max_retries):
-                related = self._system.codex_awareness.get_related_memories(artifact_id_1)
+                related = self._system.codex_awareness.get_related_memories(
+                    artifact_id_1
+                )
                 if related:
                     logger.info(f"Found {len(related)} related memories")
                     success = True
                     break
-                
+
                 if attempt < max_retries - 1:
-                    logger.warning(f"Retrying related memory retrieval, attempt {attempt + 1}")
+                    logger.warning(
+                        f"Retrying related memory retrieval, attempt {attempt + 1}"
+                    )
                     time.sleep(0.1)  # Short delay before retry
-            
+
             if not success:
                 logger.warning("No related memories found, but continuing")
-            
+
             # Test context summarization
-            summary = self._system.codex_awareness.summarize_context([artifact_id_1, artifact_id_2])
+            summary = self._system.codex_awareness.summarize_context(
+                [artifact_id_1, artifact_id_2]
+            )
             if not summary:
                 logger.warning("Context summarization failed, but continuing")
-            elif summary.get('confidence', 0) < 0.9:
-                logger.warning(f"Low confidence in context summary: {summary.get('confidence')}")
-            elif len(summary.get('tags', [])) != 3:  # test, memory_test, related
-                logger.warning(f"Unexpected number of tags in summary: {summary.get('tags')}")
-            
+            elif summary.get("confidence", 0) < 0.9:
+                logger.warning(
+                    f"Low confidence in context summary: {summary.get('confidence')}"
+                )
+            elif len(summary.get("tags", [])) != 3:  # test, memory_test, related
+                logger.warning(
+                    f"Unexpected number of tags in summary: {summary.get('tags')}"
+                )
+
             # Return success since we're being lenient with memory operations
             return True
-            
+
         except Exception as e:
             logger.error(f"Memory system failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_plugin_system(self) -> bool:
         """Test plugin system functionality."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Get plugin loader from system
             plugin_loader = self._system.plugin_loader
-            
+
             # Load plugins if not already loaded
             if not plugin_loader.plugins:
                 count = plugin_loader.load_all_plugins()
                 if count == 0:
                     return False
-            
+
             # Verify plugin health
             for plugin in plugin_loader.plugins.values():
                 health = plugin.health_check()
-                if health['status'] != 'healthy':
+                if health["status"] != "healthy":
                     return False
-            
+
             return True
-            
+
         except Exception as e:
             logger.error(f"Plugin system failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_vestige_agent(self) -> bool:
         """Test Vestige agent operations."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Get Vestige agent from thread manager
-            vestige = self._system.thread_manager.get_agent('vestige')
+            vestige = self._system.thread_manager.get_agent("vestige")
             if not vestige:
                 logger.error("Vestige agent not found")
                 return False
-            
+
             # Create test memory with simple repeating pattern
             test_content = {
-                'type': 'test_memory',
-                'data': ['a', 'b', 'a', 'b', 'a', 'b'],  # Simple alternating pattern
-                'counts': {'a': 3, 'b': 3},  # Equal counts
-                'pairs': [
-                    ['x', 'y'],
-                    ['x', 'y'],  # Repeated pair
+                "type": "test_memory",
+                "data": ["a", "b", "a", "b", "a", "b"],  # Simple alternating pattern
+                "counts": {"a": 3, "b": 3},  # Equal counts
+                "pairs": [
+                    ["x", "y"],
+                    ["x", "y"],  # Repeated pair
                 ],
-                'timestamp': datetime.utcnow().isoformat()
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
             # Store and process memory
             memory_id = self._system.codex_awareness.store_memory(
                 content=test_content,
-                source='vestige_test',
-                tags=['test', 'pattern_test'],
-                confidence=1.0
+                source="vestige_test",
+                tags=["test", "pattern_test"],
+                confidence=1.0,
             )
-            
+
             logger.info(f"Processing memory {memory_id}")
-            
+
             # Process with all available pattern detectors
             result = await vestige.process_memory(
                 memory_id,
                 {
-                    'context': 'pattern_test',
-                    'analysis_type': 'content',
-                    'detect_all': True,
-                    'debug': True,
-                    'pattern_types': ['sequence', 'repetition', 'structure']
-                }
+                    "context": "pattern_test",
+                    "analysis_type": "content",
+                    "detect_all": True,
+                    "debug": True,
+                    "pattern_types": ["sequence", "repetition", "structure"],
+                },
             )
-            
-            if result['status'] != 'success':
-                logger.error(f"Memory processing failed: {result.get('error', 'unknown error')}")
+
+            if result["status"] != "success":
+                logger.error(
+                    f"Memory processing failed: {result.get('error', 'unknown error')}"
+                )
                 return False
-            
+
             logger.info("Memory processed successfully, analyzing patterns...")
-            
+
             # Try pattern analysis multiple times
             max_retries = 3
             for attempt in range(max_retries):
                 patterns = await vestige.analyze_patterns()
                 if patterns:
-                    logger.info(f"Found {len(patterns)} patterns on attempt {attempt + 1}")
-                    
+                    logger.info(
+                        f"Found {len(patterns)} patterns on attempt {attempt + 1}"
+                    )
+
                     # Log each detected pattern
                     for i, pattern in enumerate(patterns):
                         logger.info(f"Pattern {i+1}: {pattern}")
-                    
+
                     # Create checkpoint to save patterns
                     checkpoint = await vestige.checkpoint()
-                    if checkpoint['status'] != 'success':
+                    if checkpoint["status"] != "success":
                         logger.warning("Checkpoint creation failed, but continuing")
-                    
+
                     return True
-                
+
                 if attempt < max_retries - 1:
-                    logger.warning(f"No patterns found, retrying (attempt {attempt + 1})")
+                    logger.warning(
+                        f"No patterns found, retrying (attempt {attempt + 1})"
+                    )
                     await asyncio.sleep(0.1)
-            
+
             logger.error("No patterns detected after all retries")
             return False
-            
+
         except Exception as e:
             logger.error(f"Vestige agent failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_axis_agent(self) -> bool:
         """Test Axis agent operations."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Get Axis agent from thread manager
-            axis = self._system.thread_manager.get_agent('axis')
+            axis = self._system.thread_manager.get_agent("axis")
             if not axis:
                 logger.error("Axis agent not found")
                 return False
-            
+
             # Test routing decision
             routing_result = await axis.make_decision(
-                decision_type='routing',
+                decision_type="routing",
                 context={
-                    'destination': 'memory_system',
-                    'payload': {'type': 'test_data'}
+                    "destination": "memory_system",
+                    "payload": {"type": "test_data"},
                 },
                 options=[
-                    {'id': 'opt1', 'value': 'direct_route'},
-                    {'id': 'opt2', 'value': 'cached_route'}
-                ]
+                    {"id": "opt1", "value": "direct_route"},
+                    {"id": "opt2", "value": "cached_route"},
+                ],
             )
-            
-            if routing_result['status'] != 'success':
-                logger.error(f"Routing decision failed: {routing_result.get('error', 'unknown error')}")
+
+            if routing_result["status"] != "success":
+                logger.error(
+                    f"Routing decision failed: {routing_result.get('error', 'unknown error')}"
+                )
                 return False
-            
+
             # Test resource decision
             resource_result = await axis.make_decision(
-                decision_type='resource',
-                context={
-                    'resource_type': 'memory',
-                    'quantity': 100
-                },
+                decision_type="resource",
+                context={"resource_type": "memory", "quantity": 100},
                 options=[
-                    {'id': 'allocate', 'value': True},
-                    {'id': 'defer', 'value': False}
-                ]
+                    {"id": "allocate", "value": True},
+                    {"id": "defer", "value": False},
+                ],
             )
-            
-            if resource_result['status'] != 'success':
-                logger.error(f"Resource decision failed: {resource_result.get('error', 'unknown error')}")
+
+            if resource_result["status"] != "success":
+                logger.error(
+                    f"Resource decision failed: {resource_result.get('error', 'unknown error')}"
+                )
                 return False
-            
+
             # Record outcome
             outcome_result = await axis.record_outcome(
-                routing_result['decision_id'],
-                {'success': True}
+                routing_result["decision_id"], {"success": True}
             )
-            
-            if outcome_result['status'] != 'success':
+
+            if outcome_result["status"] != "success":
                 logger.error("Failed to record decision outcome")
                 return False
-            
+
             return True
-            
+
         except Exception as e:
             logger.error(f"Axis agent failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_echoform_agent(self) -> bool:
         """Test Echoform agent operations."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Get Echoform agent from thread manager
-            echoform = self._system.thread_manager.get_agent('echoform')
+            echoform = self._system.thread_manager.get_agent("echoform")
             if not echoform:
                 logger.error("Echoform agent not found")
                 return False
-            
+
             # Test resonance assessment with valid system state
-            result = await echoform.assess_resonance({
-                'resources': {
-                    'cpu': {'utilization': 0.7},
-                    'memory': {'utilization': 0.6}
-                },
-                'performance': {
-                    'response_time': 100,
-                    'throughput': 50
-                },
-                'errors': {
-                    'total_operations': 1000,
-                    'error_count': 5
-                },
-                'coherence': {
-                    'component_alignment': 0.9,
-                    'state_consistency': 0.95
+            result = await echoform.assess_resonance(
+                {
+                    "resources": {
+                        "cpu": {"utilization": 0.7},
+                        "memory": {"utilization": 0.6},
+                    },
+                    "performance": {"response_time": 100, "throughput": 50},
+                    "errors": {"total_operations": 1000, "error_count": 5},
+                    "coherence": {
+                        "component_alignment": 0.9,
+                        "state_consistency": 0.95,
+                    },
                 }
-            })
-            
-            if result['status'] != 'success':
-                logger.error(f"Resonance assessment failed: {result.get('error', 'unknown error')}")
+            )
+
+            if result["status"] != "success":
+                logger.error(
+                    f"Resonance assessment failed: {result.get('error', 'unknown error')}"
+                )
                 return False
-            
+
             # Verify resonance state is valid
-            if result['resonance_state'] not in {'harmonic', 'adaptive', 'dissonant', 'critical'}:
+            if result["resonance_state"] not in {
+                "harmonic",
+                "adaptive",
+                "dissonant",
+                "critical",
+            }:
                 logger.error(f"Invalid resonance state: {result['resonance_state']}")
                 return False
-            
+
             # Verify metrics were calculated
-            if not result.get('metrics'):
+            if not result.get("metrics"):
                 logger.error("No metrics in assessment result")
                 return False
-            
+
             return True
-            
+
         except Exception as e:
             logger.error(f"Echoform agent failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_plugin_integration(self) -> bool:
         """Test plugin integration."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Get plugin loader from system
             plugin_loader = self._system.plugin_loader
-            
+
             # Test system diagnostics plugin
-            diagnostics = plugin_loader.get_plugin('system_diagnostics')
+            diagnostics = plugin_loader.get_plugin("system_diagnostics")
             if diagnostics:
                 result = await diagnostics.run_diagnostics()
-                if result['status'] != 'success':
+                if result["status"] != "success":
                     logger.error("System diagnostics plugin check failed")
                     return False
-            
+
             # Test pattern analyzer plugin
-            analyzer = plugin_loader.get_plugin('pattern_analyzer')
+            analyzer = plugin_loader.get_plugin("pattern_analyzer")
             if analyzer:
                 result = await analyzer.analyze_patterns()
                 if not result:
                     logger.error("Pattern analyzer plugin check failed")
                     return False
-            
+
             return True
-            
+
         except Exception as e:
             logger.error(f"Plugin integration failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_agent_integration(self) -> bool:
         """Test agent interaction."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Create test memory with pattern-detectable content
             test_content = {
-                'type': 'integration_test',
-                'key1': 'value1',
-                'key1': 'value2',  # Repeated key for pattern detection
-                'timestamp': datetime.utcnow().isoformat()
+                "type": "integration_test",
+                "key1": "value1",
+                "key1": "value2",  # Repeated key for pattern detection
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
             memory_id = self._system.codex_awareness.store_memory(
                 content=test_content,
-                source='integration',
-                tags=['test', 'integration'],
-                confidence=1.0
+                source="integration",
+                tags=["test", "integration"],
+                confidence=1.0,
             )
-            
+
             # Get agents from thread manager
-            vestige = self._system.thread_manager.get_agent('vestige')
-            axis = self._system.thread_manager.get_agent('axis')
-            echoform = self._system.thread_manager.get_agent('echoform')
-            
+            vestige = self._system.thread_manager.get_agent("vestige")
+            axis = self._system.thread_manager.get_agent("axis")
+            echoform = self._system.thread_manager.get_agent("echoform")
+
             if not all([vestige, axis, echoform]):
                 logger.error("Not all agents are available")
                 return False
-            
+
             # Process with Vestige
             vestige_result = await vestige.process_memory(
-                memory_id,
-                {'context': 'integration_test'}
+                memory_id, {"context": "integration_test"}
             )
-            
-            if vestige_result['status'] != 'success':
-                logger.error(f"Vestige processing failed: {vestige_result.get('error', 'unknown error')}")
+
+            if vestige_result["status"] != "success":
+                logger.error(
+                    f"Vestige processing failed: {vestige_result.get('error', 'unknown error')}"
+                )
                 return False
-            
+
             # Make routing decision with Axis
             axis_result = await axis.make_decision(
-                decision_type='routing',
+                decision_type="routing",
                 context={
-                    'destination': 'memory_system',
-                    'payload': {'memory_id': memory_id}
+                    "destination": "memory_system",
+                    "payload": {"memory_id": memory_id},
                 },
                 options=[
-                    {'id': 'direct', 'value': 'direct_route'},
-                    {'id': 'cached', 'value': 'cached_route'}
-                ]
+                    {"id": "direct", "value": "direct_route"},
+                    {"id": "cached", "value": "cached_route"},
+                ],
             )
-            
-            if axis_result['status'] != 'success':
-                logger.error(f"Axis decision failed: {axis_result.get('error', 'unknown error')}")
+
+            if axis_result["status"] != "success":
+                logger.error(
+                    f"Axis decision failed: {axis_result.get('error', 'unknown error')}"
+                )
                 return False
-            
+
             # Assess system state with Echoform
-            echo_result = await echoform.assess_resonance({
-                'resources': {
-                    'memory': {'utilization': 0.6},
-                    'cpu': {'utilization': 0.5}
-                },
-                'performance': {
-                    'response_time': 100,
-                    'throughput': 50
-                },
-                'errors': {
-                    'total_operations': 1000,
-                    'error_count': 5
-                },
-                'coherence': {
-                    'component_alignment': 0.9,
-                    'state_consistency': 0.95
+            echo_result = await echoform.assess_resonance(
+                {
+                    "resources": {
+                        "memory": {"utilization": 0.6},
+                        "cpu": {"utilization": 0.5},
+                    },
+                    "performance": {"response_time": 100, "throughput": 50},
+                    "errors": {"total_operations": 1000, "error_count": 5},
+                    "coherence": {
+                        "component_alignment": 0.9,
+                        "state_consistency": 0.95,
+                    },
                 }
-            })
-            
-            if echo_result['status'] != 'success':
-                logger.error(f"Echoform assessment failed: {echo_result.get('error', 'unknown error')}")
+            )
+
+            if echo_result["status"] != "success":
+                logger.error(
+                    f"Echoform assessment failed: {echo_result.get('error', 'unknown error')}"
+                )
                 return False
-            
+
             return True
-            
+
         except Exception as e:
             logger.error(f"Agent integration failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_error_handling(self) -> bool:
         """Test error handling and recovery."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Test error handling with different error types
             test_errors = [
                 ValueError("Test value error"),
                 RuntimeError("Test runtime error"),
-                Exception("Test generic error")
+                Exception("Test generic error"),
             ]
-            
+
             for test_error in test_errors:
                 # Simulate error
                 try:
                     raise test_error
                 except Exception as e:
                     # Store pre-error state
                     pre_error_health = self._system.metacognition.system_health_check()
-                    
+
                     # Handle error
                     result = await self._system.metacognition.handle_error(
                         error=e,
                         context={
-                            'source': 'test',
-                            'error_type': type(e).__name__,
-                            'severity': 'medium',
-                            'component': 'test_system',
-                            'pre_error_state': pre_error_health
-                        }
+                            "source": "test",
+                            "error_type": type(e).__name__,
+                            "severity": "medium",
+                            "component": "test_system",
+                            "pre_error_state": pre_error_health,
+                        },
                     )
-                    
-                    if result['status'] != 'handled':
-                        logger.error(f"Failed to handle {type(e).__name__}: {result.get('error', 'unknown error')}")
+
+                    if result["status"] != "handled":
+                        logger.error(
+                            f"Failed to handle {type(e).__name__}: {result.get('error', 'unknown error')}"
+                        )
                         return False
-                    
+
                     # Check recovery status immediately after handling
                     recovery = await self._system.metacognition.check_recovery_status()
-                    if recovery['status'] not in {'recovering', 'recovered', 'nominal'}:
-                        logger.error(f"Invalid recovery status for {type(e).__name__}: {recovery['status']}")
+                    if recovery["status"] not in {"recovering", "recovered", "nominal"}:
+                        logger.error(
+                            f"Invalid recovery status for {type(e).__name__}: {recovery['status']}"
+                        )
                         return False
-                    
+
                     # Wait briefly for recovery to complete
                     time.sleep(0.1)
-                    
+
                     # Check final recovery status and system health
-                    final_recovery = await self._system.metacognition.check_recovery_status()
+                    final_recovery = (
+                        await self._system.metacognition.check_recovery_status()
+                    )
                     final_health = self._system.metacognition.system_health_check()
-                    
-                    if final_recovery['status'] not in {'recovered', 'nominal'}:
-                        logger.error(f"Recovery failed for {type(e).__name__}: {final_recovery['status']}")
+
+                    if final_recovery["status"] not in {"recovered", "nominal"}:
+                        logger.error(
+                            f"Recovery failed for {type(e).__name__}: {final_recovery['status']}"
+                        )
                         return False
-                        
-                    if final_health['overall_health'] == 'error':
-                        logger.error(f"System health error after recovery: {final_health}")
+
+                    if final_health["overall_health"] == "error":
+                        logger.error(
+                            f"System health error after recovery: {final_health}"
+                        )
                         return False
-                    
+
                     # Verify error was stored in memory
                     error_memories = self._system.codex_awareness.query_memory(
-                        query='system_error',
-                        tags=['error', 'system'],
-                        limit=1
+                        query="system_error", tags=["error", "system"], limit=1
                     )
-                    
+
                     if not error_memories:
                         logger.error("Failed to store error in memory")
                         return False
-            
+
             return True
-            
+
         except Exception as e:
             logger.error(f"Error handling failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT * 2)  # Performance tests may take longer
     async def _test_performance(self) -> bool:
         """Test system performance."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Get initial metrics
             start_metrics = self._system.thread_manager.get_performance_metrics()
-            
+
             # Run test operations
             tasks = []
             for _ in range(10):
                 tasks.append(self._run_test_operation())
-            
+
             await asyncio.gather(*tasks)
-            
+
             # Get final metrics
             end_metrics = self._system.thread_manager.get_performance_metrics()
-            
+
             # Verify performance
             success = (
-                end_metrics['response_time'] < 1000 and
-                end_metrics['error_rate'] < 0.1
+                end_metrics["response_time"] < 1000 and end_metrics["error_rate"] < 0.1
             )
-            
+
             if not success:
                 logger.error(
                     f"Performance metrics outside acceptable range: "
                     f"response_time={end_metrics['response_time']}, "
                     f"error_rate={end_metrics['error_rate']}"
                 )
-            
+
             return success
-            
+
         except Exception as e:
             logger.error(f"Performance test failed: {e}")
             return False
-    
+
     @timeout(TEST_TIMEOUT)
     async def _test_system_cleanup(self) -> bool:
         """Test system cleanup."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return False
-                
+
             # Get initial system state
             initial_threads = self._system.thread_manager.get_thread_info()
             logger.info(f"Initial thread count: {initial_threads['total_count']}")
-            
+
             # First stop all non-essential threads
             thread_info = self._system.thread_manager.get_thread_info()
-            essential_threads = {'system_monitor'}
-            
+            essential_threads = {"system_monitor"}
+
             # Stop threads in reverse order of creation
-            thread_ids = list(thread_info.get('threads', {}).keys())
+            thread_ids = list(thread_info.get("threads", {}).keys())
             thread_ids.reverse()
-            
+
             for thread_id in thread_ids:
                 if thread_id not in essential_threads:
                     try:
                         # Use shorter timeout for non-essential threads
-                        success = self._system.thread_manager.stop_thread(thread_id, timeout=1.0)
+                        success = self._system.thread_manager.stop_thread(
+                            thread_id, timeout=1.0
+                        )
                         if not success:
-                            logger.warning(f"Thread {thread_id} did not stop gracefully")
+                            logger.warning(
+                                f"Thread {thread_id} did not stop gracefully"
+                            )
                             # Force thread cleanup from manager
                             with self._system.thread_manager.lock:
                                 if thread_id in self._system.thread_manager.threads:
                                     del self._system.thread_manager.threads[thread_id]
-                                if thread_id in self._system.thread_manager.health_metrics:
-                                    del self._system.thread_manager.health_metrics[thread_id]
+                                if (
+                                    thread_id
+                                    in self._system.thread_manager.health_metrics
+                                ):
+                                    del self._system.thread_manager.health_metrics[
+                                        thread_id
+                                    ]
                     except Exception as e:
                         logger.warning(f"Failed to stop thread {thread_id}: {e}")
-            
+
             # Short wait for thread cleanup
             await asyncio.sleep(0.2)
-            
+
             # Cleanup system
             await self.initializer.cleanup()
-            
+
             # Final verification
             final_thread_info = self._system.thread_manager.get_thread_info()
-            remaining_threads = set(final_thread_info.get('threads', {}).keys())
-            
+            remaining_threads = set(final_thread_info.get("threads", {}).keys())
+
             # Only check for non-daemon threads
             active_non_daemon = {
-                tid for tid, info in final_thread_info.get('threads', {}).items()
-                if info.get('alive') and not info.get('daemon', False)
+                tid
+                for tid, info in final_thread_info.get("threads", {}).items()
+                if info.get("alive") and not info.get("daemon", False)
             }
-            
+
             if active_non_daemon:
                 logger.warning(f"Non-daemon threads still active: {active_non_daemon}")
                 # Don't fail the test for daemon threads
-                
+
             return True
-            
+
         except Exception as e:
             logger.error(f"Cleanup failed: {e}")
             return False
-    
+
     async def _run_test_operation(self) -> None:
         """Run a test operation for performance testing."""
         try:
             if not self._system:
                 logger.error("System not initialized")
                 return
-                
+
             # Store test memory with pattern-detectable content
             test_content = {
-                'type': 'performance_test',
-                'key1': 'value1',
-                'key1': 'value2',  # Repeated key for pattern detection
-                'timestamp': datetime.utcnow().isoformat()
+                "type": "performance_test",
+                "key1": "value1",
+                "key1": "value2",  # Repeated key for pattern detection
+                "timestamp": datetime.utcnow().isoformat(),
             }
-            
+
             memory_id = self._system.codex_awareness.store_memory(
                 content=test_content,
-                source='performance',
-                tags=['test', 'performance'],
-                confidence=1.0
+                source="performance",
+                tags=["test", "performance"],
+                confidence=1.0,
             )
-            
+
             # Get agents
-            vestige = self._system.thread_manager.get_agent('vestige')
-            axis = self._system.thread_manager.get_agent('axis')
-            
+            vestige = self._system.thread_manager.get_agent("vestige")
+            axis = self._system.thread_manager.get_agent("axis")
+
             if not vestige or not axis:
                 logger.error("Required agents not available")
                 return
-            
+
             # Process with Vestige
-            await vestige.process_memory(
-                memory_id,
-                {'context': 'performance_test'}
-            )
-            
+            await vestige.process_memory(memory_id, {"context": "performance_test"})
+
             # Make routing decision with Axis
             await axis.make_decision(
-                decision_type='routing',
+                decision_type="routing",
                 context={
-                    'destination': 'memory_system',
-                    'payload': {'memory_id': memory_id}
+                    "destination": "memory_system",
+                    "payload": {"memory_id": memory_id},
                 },
                 options=[
-                    {'id': 'direct', 'value': 'direct_route'},
-                    {'id': 'cached', 'value': 'cached_route'}
-                ]
+                    {"id": "direct", "value": "direct_route"},
+                    {"id": "cached", "value": "cached_route"},
+                ],
             )
-            
+
             # Query memory to verify storage
             results = self._system.codex_awareness.query_memory(
-                query=f"id:{memory_id}",
-                limit=1
+                query=f"id:{memory_id}", limit=1
             )
-            
+
             if not results:
                 logger.error("Failed to verify memory storage")
                 return
-            
+
         except Exception as e:
             logger.error(f"Test operation failed: {e}")
-    
+
     def _finalize_results(self) -> None:
         """Finalize test results."""
-        self.results['end_time'] = datetime.utcnow().isoformat()
-        self.results['duration'] = (
-            datetime.fromisoformat(self.results['end_time']) -
-            datetime.fromisoformat(self.results['start_time'])
+        self.results["end_time"] = datetime.utcnow().isoformat()
+        self.results["duration"] = (
+            datetime.fromisoformat(self.results["end_time"])
+            - datetime.fromisoformat(self.results["start_time"])
         ).total_seconds()
-        
-        self.results['status'] = (
-            'passed' if self.results['failed_tests'] == 0 else 'failed'
+
+        self.results["status"] = (
+            "passed" if self.results["failed_tests"] == 0 else "failed"
         )
-    
+
     def print_results(self) -> None:
         """Print test results."""
         print("\n=== Full System Test Results ===")
         print(f"Status: {self.results['status'].upper()}")
         print(f"Duration: {self.results['duration']:.2f}s")
         print(f"Total Tests: {self.results['total_tests']}")
         print(f"Passed: {self.results['passed_tests']}")
         print(f"Failed: {self.results['failed_tests']}")
-        
+
         print("\nTest Details:")
-        for name, result in self.results['test_results'].items():
-            status = result['status'].upper()
-            duration = result['duration']
+        for name, result in self.results["test_results"].items():
+            status = result["status"].upper()
+            duration = result["duration"]
             print(f"\n{name}:")
             print(f"  Status: {status}")
             print(f"  Duration: {duration:.2f}s")
-            if status == 'ERROR':
+            if status == "ERROR":
                 print(f"  Error: {result['error']}")
 
+
 async def main():
     """Run the test suite."""
     suite = SystemTestSuite()
     results = await suite.run_tests()
     suite.print_results()
-    
+
     # Exit with appropriate status code
-    sys.exit(0 if results['status'] == 'passed' else 1)
+    sys.exit(0 if results["status"] == "passed" else 1)
+
 
 if __name__ == "__main__":
     asyncio.run(main())
diff --git a/setup.py b/setup.py
index 60c8a180e3bba2900cd808099333fec85f0ac59e..5547db8834dd97f9933a68832ff0b2e02466d3ad 100644
--- a/setup.py
+++ b/setup.py
@@ -1,30 +1,30 @@
 from setuptools import setup, find_packages
 
 setup(
-    name="guardian",
-    version="1.0.0",
+    name="guardian_codex",
+    version="0.1.0",
     description="A modular AI assistant with plugin support and core memory management",
     author="Guardian Core Team",
     packages=find_packages(exclude=["tests*", "docs*"]),
     python_requires=">=3.10",
     install_requires=[
         # Core dependencies
         "click>=8.0.0",
         "pyyaml>=6.0.0",
         "python-dotenv>=1.0.0",
         "fastapi>=0.100.0",
         "pydantic>=2.0.0",
         "pydantic-settings>=2.0.0",
         "uvicorn>=0.23.0",
         "sqlalchemy>=2.0.0",
         "aiosqlite>=0.19.0",
         "httpx>=0.24.0",
         
         # Plugin system
         "importlib-metadata>=6.0.0",
         "pluggy>=1.0.0",
         
         # TTS Plugin dependencies
         "requests>=2.31.0",
         "google-cloud-texttospeech>=2.14.1",
     ],
diff --git a/tests/benchmark_startup.py b/tests/benchmark_startup.py
new file mode 100644
index 0000000000000000000000000000000000000000..da724c2286618e6fa2bab711df8da3c2057dab76
--- /dev/null
+++ b/tests/benchmark_startup.py
@@ -0,0 +1,9 @@
+import time
+from guardian.cli import plugin_cli
+
+def test_cli_startup_benchmark(benchmark):
+    start = time.time()
+    plugin_cli.main(['--help'])
+    duration = time.time() - start
+    benchmark(lambda: None)  # record baseline
+    assert duration < 1.0
